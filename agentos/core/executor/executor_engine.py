"""
Executor Engine - æ‰§è¡Œç¼–æ’å¼•æ“

ç¼–æ’æ‰€æœ‰ç»„ä»¶å®ŒæˆçœŸå®æ‰§è¡Œ
"""

from pathlib import Path
from typing import Dict, Any, Optional, List
from datetime import datetime, timezone
import hashlib
import json

from .allowlist import Allowlist
from .sandbox import Sandbox
from .rollback import RollbackManager
from .lock import ExecutionLock
from .review_gate import ReviewGate
from .audit_logger import AuditLogger
from .sandbox_policy import SandboxPolicyLoader, PolicyDeniedError
from .run_tape import RunTape
from ..infra.git_client import GitClientFactory

# ğŸ”© M1 ç»‘å®šç‚¹ï¼šå¯¼å…¥ Mode Systemï¼ˆæœ€å°åŒ–ï¼‰
from agentos.core.mode import get_mode, ModeViolationError
from agentos.core.mode.mode_alerts import alert_mode_violation, AlertSeverity
# Task 27: Mode Event Listener integration
from agentos.core.mode.mode_event_listener import emit_mode_violation

# Task-Driven: Import TaskManager
from agentos.core.task import TaskManager

# Task #3: Planning Guard - v0.6 Soul
from agentos.core.task.planning_guard import get_planning_guard
from agentos.core.task.errors import PlanningSideEffectForbiddenError
from agentos.core.time import utc_now_iso



class DiffRejected(Exception):
    """
    ğŸ”© H3-2ï¼šDiff éªŒè¯å¤±è´¥å¼‚å¸¸
    
    å½“ DiffVerifier éªŒè¯å¤±è´¥æ—¶æŠ›å‡ºï¼Œé˜²æ­¢æœªéªŒè¯çš„ diff è¢«åº”ç”¨ã€‚
    """
    def __init__(self, reason: str, validation: Any):
        super().__init__(reason)
        self.reason = reason
        self.validation = validation


class ExecutorEngine:
    """æ‰§è¡Œå¼•æ“ - ç¼–æ’æ‰€æœ‰ç»„ä»¶"""
    
    def __init__(
        self,
        repo_path: Path,
        output_dir: Path,
        lock_dir: Optional[Path] = None,
        approval_dir: Optional[Path] = None
    ):
        """
        åˆå§‹åŒ–æ‰§è¡Œå¼•æ“
        
        Args:
            repo_path: Gitä»“åº“è·¯å¾„
            output_dir: è¾“å‡ºç›®å½•
            lock_dir: é”ç›®å½•
            approval_dir: å®¡æ‰¹ç›®å½•
        
        æ³¨æ„: use_sandbox å‚æ•°å·²ç§»é™¤ï¼Œå¼ºåˆ¶ä½¿ç”¨ worktree
        """
        self.repo_path = Path(repo_path)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.allowlist = Allowlist()
        self.sandbox: Optional[Sandbox] = None
        self.rollback_manager = RollbackManager(repo_path)
        self.lock = ExecutionLock(lock_dir or (output_dir / "locks"))
        self.review_gate = ReviewGate(approval_dir or (output_dir / "approvals"))
        self.audit_logger: Optional[AuditLogger] = None
        self.task_manager = TaskManager()  # Task-Driven
        self.planning_guard = get_planning_guard()  # Task #3: Planning Guard
    
    def execute(
        self,
        execution_request: Dict[str, Any],
        sandbox_policy: Dict[str, Any],
        policy_path: Optional[Path] = None,
        caller_source: str = "unknown"
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œè¯·æ±‚

        Task #1: Chat â†’ Execution Hard Gate
        Added caller_source parameter to enforce source verification.
        Only "task_runner" is allowed to execute. "chat" will be rejected.

        Args:
            execution_request: æ‰§è¡Œè¯·æ±‚
            sandbox_policy: sandboxç­–ç•¥ (deprecated, use policy_path)
            policy_path: ç­–ç•¥æ–‡ä»¶è·¯å¾„ï¼ˆæ–°å‚æ•°ï¼‰
            caller_source: Source of the call - MUST be "task_runner" for execution
                          Options: "task_runner", "chat", "unknown"

        Returns:
            æ‰§è¡Œç»“æœ

        Raises:
            ChatExecutionForbiddenError: If caller_source is "chat"
        """
        # Task #1: Hard gate - reject chat execution attempts
        # Import here to avoid circular import
        if caller_source == "chat":
            from agentos.core.task.errors import ChatExecutionForbiddenError
            raise ChatExecutionForbiddenError(
                caller_context="ExecutorEngine.execute",
                attempted_operation="execute_task",
                task_id=execution_request.get("task_id"),
                metadata={
                    "execution_request_id": execution_request.get("execution_request_id"),
                    "enforcement": "hard_gate_task_1"
                }
            )

        # Task #1: Enforce that only task_runner can execute
        if caller_source != "task_runner":
            logger.warning(
                f"Execution called with non-task_runner source: {caller_source}. "
                f"This should only be called by task runner."
            )
        exec_req_id = execution_request["execution_request_id"]
        run_dir = self.output_dir / exec_req_id
        run_dir.mkdir(parents=True, exist_ok=True)
        
        # P0-RT2: RunTape å¿…é¡»ä»ç¬¬ä¸€è¡Œå¼€å§‹å†™ï¼ˆæœ€å¤–å±‚åˆå§‹åŒ–ï¼‰
        audit_dir = run_dir / "audit"
        audit_dir.mkdir(parents=True, exist_ok=True)
        run_tape = RunTape(audit_dir)
        
        # Task-Driven: Extract or create task_id (P0: Orphan å®¹é”™)
        task_id = execution_request.get("task_id")
        if not task_id:
            # ğŸš¨ P0 å®¹é”™ï¼šæ—  task_id æ—¶åˆ›å»º orphan
            run_tape.audit_logger.log_warning(
                "execution_without_task_id",
                details={
                    "execution_request_id": exec_req_id,
                    "action": "creating_orphan_task",
                    "reason": "execution_request missing task_id"
                }
            )
            task = self.task_manager.create_orphan_task(
                ref_id=exec_req_id,
                created_by="executor_engine"
            )
            task_id = task.task_id
            run_tape.audit_logger.log_event(
                "orphan_task_created",
                details={
                    "task_id": task_id,
                    "orphan_ref": exec_req_id
                }
            )

        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Task #4: EXECUTION FROZEN PLAN VALIDATION (v0.6 Core)
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # Executor only trusts frozen specs. Execution MUST be blocked if
        # spec_frozen = 0. This is a hard gate enforcing v0.6 architecture.
        #
        # Validation:
        #   - Load task from database
        #   - Check task.spec_frozen == 1
        #   - If spec_frozen = 0 â†’ raise SpecNotFrozenError
        #   - Audit rejection reason
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        task = self.task_manager.get_task(task_id)
        if not task:
            # Task not found - create error result
            error_msg = f"Task {task_id} not found in database"
            run_tape.audit_logger.log_error(error_msg)
            return self._create_error_result(
                exec_req_id,
                "failed",
                error_msg,
                run_tape,
                run_dir
            )

        # Task #4: Check spec_frozen flag
        if not task.is_spec_frozen():
            from agentos.core.task.errors import SpecNotFrozenError

            # Audit rejection
            run_tape.audit_logger.log_event("execution_blocked_spec_not_frozen", details={
                "task_id": task_id,
                "spec_frozen": task.spec_frozen,
                "reason": "Execution requires frozen specification (spec_frozen = 1)",
                "enforcement": "task_4_frozen_plan_validation",
                "v06_constraint": True
            })

            # Raise error with clear message
            raise SpecNotFrozenError(
                task_id=task_id,
                reason="Execution requires frozen specification. Please freeze spec before executing.",
                metadata={
                    "execution_request_id": exec_req_id,
                    "spec_frozen": task.spec_frozen,
                    "enforcement": "task_4_frozen_plan_validation"
                }
            )

        # Log successful validation
        run_tape.audit_logger.log_event("spec_frozen_validation_passed", details={
            "task_id": task_id,
            "spec_frozen": task.spec_frozen,
            "validation": "passed"
        })
        
        # ä¿æŒå‘åå…¼å®¹ï¼šåŒæ—¶ä½¿ç”¨ AuditLogger
        self.audit_logger = run_tape.audit_logger
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # INTEGRATOR FREEZE (Agent 4): Mode å…¥å£å”¯ä¸€æ€§ä¿è¯
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # æ­¤å¤„æ˜¯ Executor è·å– mode çš„å”¯ä¸€å…¥å£ç‚¹ã€‚
        # 
        # éªŒæ”¶å‘½ä»¤:
        #   rg "get_mode\(" agentos/core/executor | wc -l
        #   æœŸæœ›ç»“æœ: 2ï¼ˆexecute + apply_diff_or_raiseï¼‰
        #
        # ç¦æ­¢:
        #   - åœ¨å…¶ä»–åœ°æ–¹å·å·è°ƒç”¨ get_mode()
        #   - åˆ›å»ºé»˜è®¤ silent mode
        #   - ç»•è¿‡æ­¤å…¥å£è·å– mode
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ”© M1 ç»‘å®šç‚¹ï¼šè·å– mode_idï¼ˆé»˜è®¤ implementationï¼‰
        mode_id = execution_request.get("mode_id", "implementation")
        mode_defaulted = "mode_id" not in execution_request
        
        try:
            mode = get_mode(mode_id)
        except Exception as e:
            run_tape.audit_logger.log_error(f"Invalid mode_id '{mode_id}': {e}")
            return self._create_error_result(
                exec_req_id,
                "failed",
                f"Invalid mode_id '{mode_id}': {e}",
                run_tape,
                run_dir
            )
        
        # è®°å½• mode ä¿¡æ¯
        run_tape.audit_logger.log_event("mode_resolved", details={
            "mode_id": mode_id,
            "mode_defaulted": mode_defaulted,
            "allows_commit": mode.allows_commit(),
            "allows_diff": mode.allows_diff()
        })
        
        # ä¿å­˜ mode_id åˆ°å®ä¾‹å˜é‡ï¼ˆä¾› apply_diff_or_raise ä½¿ç”¨ï¼‰
        self._current_mode_id = mode_id
        
        # è®°å½•æ‰§è¡Œå¼€å§‹
        run_tape.audit_logger.log_event("execution_start", details={
            "execution_request_id": exec_req_id,
            "task_id": task_id,  # Include task_id in audit
            "mode": mode_id,
            "started_at": utc_now_iso()
        })
        
        # Task-Driven: Record execution_request to lineage
        self.task_manager.add_lineage(
            task_id=task_id,
            kind="execution_request",
            ref_id=exec_req_id,
            phase="execution"
        )

        # Task #3: Store task_id for planning guard checks
        self._current_task_id = task_id
        
        # P0-RT1: Policy åœ¨æ‰§è¡Œå‰è¢«åŠ è½½å¹¶å¼ºåˆ¶
        policy = None
        if policy_path:
            try:
                policy_loader = SandboxPolicyLoader()
                policy = policy_loader.load(policy_path)
                
                run_tape.audit_logger.log_event("policy_loaded", details={
                    "policy_id": policy.policy_id,
                    "policy_path": str(policy_path),
                    "schema_version": policy.schema_version
                })
            except Exception as e:
                run_tape.audit_logger.log_event("policy_load_failed", details={
                    "error": str(e),
                    "policy_path": str(policy_path)
                })
                return self._create_error_result(
                    exec_req_id,
                    "failed",
                    f"Policy load failed: {str(e)}",
                    run_tape,
                    run_dir
                )
        
        # è®°å½•åˆå§‹çŠ¶æ€
        started_at = utc_now_iso()
        
        try:
            # 1. æ£€æŸ¥æ˜¯å¦éœ€è¦å®¡æ‰¹
            if self.review_gate.requires_review(execution_request):
                approval = self.review_gate.check_approval(exec_req_id)
                if not approval:
                    run_tape.audit_logger.log_error("Execution requires approval but none found")
                    return self._create_error_result(
                        exec_req_id,
                        "blocked",
                        "Requires approval",
                        run_tape,
                        run_dir
                    )
            
            # 2. è·å–é”
            repo_hash = hashlib.sha256(str(self.repo_path).encode()).hexdigest()[:16]
            if not self.lock.acquire(exec_req_id, repo_hash):
                run_tape.audit_logger.log_error("Failed to acquire lock - concurrent execution detected")
                return self._create_error_result(
                    exec_req_id,
                    "failed",
                    "Failed to acquire lock",
                    run_tape,
                    run_dir
                )
            
            # P0-RT3: Worktree å¿…é¡»å¼ºåˆ¶ï¼ˆè®°å½• base_commitï¼‰
            main_git = GitClientFactory.get_client(self.repo_path)
            base_commit = main_git.get_head_sha()
            
            # 3. åˆ›å»ºsandbox (worktree) - å¼ºåˆ¶ä½¿ç”¨
            self.sandbox = Sandbox(self.repo_path)
            worktree_path = self.sandbox.create_worktree(exec_req_id)
            
            run_tape.audit_logger.log_event("sandbox_created", details={
                "worktree_path": str(worktree_path),
                "mode": "worktree_isolated",
                "base_commit": base_commit[:8]
            })
            
            # 4. åˆ›å»ºå›æ»šç‚¹
            rollback_point = self.rollback_manager.create_rollback_point("pre_execution", worktree_path)
            run_tape.audit_logger.log_event("rollback_point_created", details=rollback_point)
            
            # 5. æ‰§è¡Œæ“ä½œï¼ˆçœŸå®æ‰§è¡Œï¼‰- æ¯ä¸ª operation éƒ½è¦è¿‡ policy æ£€æŸ¥
            operations_executed = []
            
            # æ”¯æŒä¸¤ç§æ ¼å¼ï¼š
            # 1. execution_request["allowed_operations"] (æ—§æ ¼å¼)
            # 2. execution_request["patch_plan"]["steps"][]["operations"] (æ–°æ ¼å¼)
            
            if "patch_plan" in execution_request:
                # æ–°æ ¼å¼ï¼šéå† patch_plan steps
                steps = execution_request["patch_plan"]["steps"]
                for step in steps:
                    for op in step.get("operations", []):
                        # P0-RT1: Policy æ£€æŸ¥ï¼ˆdeny ç›´æ¥æŠ›å¼‚å¸¸ï¼‰
                        if policy:
                            try:
                                action = op.get("action")
                                params = op.get("params", {})
                                policy.assert_operation_allowed(action, params)
                            except PolicyDeniedError as e:
                                # è®°å½• policy_denied äº‹ä»¶
                                run_tape.audit_logger.log_event("policy_denied", details={
                                    "operation": e.operation,
                                    "reason": e.reason,
                                    "rule_id": e.rule_id,
                                    "params": params
                                })
                                raise  # é‡æ–°æŠ›å‡ºï¼Œäº¤ç»™å¤–å±‚ except å¤„ç†
                        
                        result = self._execute_operation(op, worktree_path)
                        operations_executed.append(result)
            else:
                # æ—§æ ¼å¼ï¼šç›´æ¥éå† allowed_operations
                allowed_ops = execution_request.get("allowed_operations", [])
                for i, op in enumerate(allowed_ops):
                    op_id = f"op_{i+1:03d}"
                    
                    # P0-RT1: Policy æ£€æŸ¥
                    if policy:
                        try:
                            action = op.get("action")
                            params = op.get("params", {})
                            policy.assert_operation_allowed(action, params)
                        except PolicyDeniedError as e:
                            run_tape.audit_logger.log_event("policy_denied", details={
                                "operation": e.operation,
                                "reason": e.reason,
                                "rule_id": e.rule_id,
                                "params": params
                            })
                            raise
                    
                    result = self._execute_operation(op, worktree_path, op_id)
                    operations_executed.append(result)
            
            # 6. å®Œæˆ
            run_tape.audit_logger.log_event("execution_complete")
            
            # 7. P0-RT3: å°† worktree çš„ commits å¸¦å›ä¸» repoï¼ˆå¼ºåˆ¶æ‰§è¡Œï¼‰
            commits_brought_back = 0
            patches_generated = 0
            
            if self.sandbox and worktree_path != self.repo_path:
                commits_brought_back, patches_generated = self._bring_back_commits_from_worktree(
                    worktree_path,
                    base_commit,
                    rollback_point,
                    run_dir,
                    exec_req_id,
                    policy  # ğŸ”© H3-2 æ”¶å£2ï¼šä¼ é€’ policy ç”¨äº allowed_paths
                )
            
            completed_at = utc_now_iso()
            
            execution_result = {
                "execution_result_id": f"exec_result_{exec_req_id}",
                "schema_version": "0.11.1",
                "execution_request_id": exec_req_id,
                "task_id": task_id,  # Include task_id
                "status": "success",
                "operations_executed": operations_executed,
                "rollback_point": rollback_point,
                "commits_brought_back": commits_brought_back,
                "patches_generated": patches_generated,
                "started_at": started_at,
                "completed_at": completed_at,
                "mode": mode_id,
            }
            
            # Task-Driven: Record commits to lineage
            if commits_brought_back > 0:
                # Extract commit hashes from operations
                for op in operations_executed:
                    if op.get("type") == "git_commit" and op.get("commit_hash"):
                        self.task_manager.add_lineage(
                            task_id=task_id,
                            kind="commit",
                            ref_id=op["commit_hash"],
                            phase="completed"
                        )
            
            # Update task status
            self.task_manager.update_task_status(task_id, "succeeded")
            
            # P0-RT2: ç”Ÿæˆ execution_summary.json
            self._generate_execution_summary(
                run_dir,
                exec_req_id,
                "success",
                commits_brought_back,
                patches_generated,
                started_at,
                completed_at
            )
            
            # P0-RT2: ç”Ÿæˆ checksums.json
            self._generate_checksums(audit_dir, run_tape)
            
            # ä¿å­˜ç»“æœ
            result_file = run_dir / "execution_result.json"
            with open(result_file, "w", encoding="utf-8") as f:
                json.dump(execution_result, f, indent=2)
            
            return execution_result
            
        except PolicyDeniedError as e:
            # P0-RT1: Policy æ‹’ç»å¿…é¡»æ˜ç¡®è®°å½•
            run_tape.audit_logger.log_error(f"Policy denied: {e.reason}")

            completed_at = utc_now_iso()

            # P0-RT2: ç”Ÿæˆ execution_summary.jsonï¼ˆå³ä½¿å¤±è´¥ï¼‰
            self._generate_execution_summary(
                run_dir,
                exec_req_id,
                "denied",
                0,
                0,
                started_at,
                completed_at,
                error=str(e)
            )

            # P0-RT2: ç”Ÿæˆ checksums.jsonï¼ˆå³ä½¿å¤±è´¥ï¼‰
            self._generate_checksums(audit_dir, run_tape)

            # Task-Driven: Update task status
            self.task_manager.update_task_status(task_id, "failed")

            return {
                "execution_result_id": f"exec_result_{exec_req_id}",
                "schema_version": "0.11.1",
                "execution_request_id": exec_req_id,
                "task_id": task_id,
                "status": "denied",
                "error": str(e),
                "policy_denied": {
                    "operation": e.operation,
                    "reason": e.reason,
                    "rule_id": e.rule_id
                },
                "started_at": started_at,
                "completed_at": completed_at
            }

        except Exception as e:
            # Task #4: Check if this is SpecNotFrozenError
            from agentos.core.task.errors import SpecNotFrozenError
            if isinstance(e, SpecNotFrozenError):
                run_tape.audit_logger.log_error(f"Spec not frozen: {e.reason}")

                completed_at = utc_now_iso()

                # Generate execution_summary.json
                self._generate_execution_summary(
                    run_dir,
                    exec_req_id,
                    "blocked",
                    0,
                    0,
                    started_at,
                    completed_at,
                    error=str(e)
                )

                # Generate checksums.json
                self._generate_checksums(audit_dir, run_tape)

                # Task-Driven: Update task status to blocked
                self.task_manager.update_task_status(task_id, "blocked")

                return {
                    "execution_result_id": f"exec_result_{exec_req_id}",
                    "schema_version": "0.11.1",
                    "execution_request_id": exec_req_id,
                    "task_id": task_id,
                    "status": "blocked",
                    "error": str(e),
                    "spec_not_frozen": {
                        "reason": e.reason,
                        "task_id": e.task_id,
                        "enforcement": "task_4_frozen_plan_validation"
                    },
                    "started_at": started_at,
                    "completed_at": completed_at
                }

            # Generic exception handler (original code)
            run_tape.audit_logger.log_error(str(e))
            
        except Exception as e:
            run_tape.audit_logger.log_error(str(e))
            
            # å°è¯•å›æ»š
            if self.rollback_manager.rollback_points:
                run_tape.audit_logger.log_rollback("execution_failed", self.rollback_manager.rollback_points[-1])
                self.rollback_manager.rollback_to_latest()
            
            completed_at = utc_now_iso()
            
            # P0-RT2: ç”Ÿæˆ execution_summary.jsonï¼ˆå³ä½¿å¤±è´¥ï¼‰
            self._generate_execution_summary(
                run_dir,
                exec_req_id,
                "failed",
                0,
                0,
                started_at,
                completed_at,
                error=str(e)
            )
            
            # P0-RT2: ç”Ÿæˆ checksums.jsonï¼ˆå³ä½¿å¤±è´¥ï¼‰
            self._generate_checksums(audit_dir, run_tape)
            
            # Task-Driven: Update task status
            self.task_manager.update_task_status(task_id, "failed")
            
            return {
                "execution_result_id": f"exec_result_{exec_req_id}",
                "schema_version": "0.11.1",
                "execution_request_id": exec_req_id,
                "task_id": task_id,
                "status": "failed",
                "error": str(e),
                "started_at": started_at,
                "completed_at": completed_at
            }
            
        finally:
            # æ¸…ç†ï¼ˆå§‹ç»ˆæ‰§è¡Œï¼‰
            if self.sandbox:
                self.sandbox.remove_worktree()
            
            self.lock.release()
    
    def _execute_operation(
        self,
        op: Dict[str, Any],
        worktree_path: Path,
        op_id: Optional[str] = None,
        skip_planning_guard: bool = False
    ) -> Dict[str, Any]:
        """
        æ‰§è¡Œå•ä¸ªæ“ä½œ

        Task #3: Planning Guard integrated here
        Task #10: Added skip_planning_guard parameter with audit logging

        All operations must pass planning guard check before execution.

        Args:
            op: æ“ä½œå®šä¹‰
            worktree_path: worktree è·¯å¾„
            op_id: æ“ä½œ IDï¼ˆå¯é€‰ï¼‰
            skip_planning_guard: Skip planning guard check (default False)
                                 WARNING: Bypassing guard will be audited

        Returns:
            æ“ä½œç»“æœ
        """
        if op_id is None:
            op_id = op.get("op_id", "unknown")

        action = op.get("action")
        params = op.get("params", {})

        # Task #10: Audit if planning guard is being skipped
        if skip_planning_guard:
            task_id = getattr(self, '_current_task_id', None)
            self.audit_logger.log_event("planning_guard_skipped", details={
                "task_id": task_id,
                "op_id": op_id,
                "action": action,
                "caller": "executor_engine._execute_operation",
                "reason": "skip_planning_guard=True",
                "warning": "Planning guard bypass detected - this operation is NOT protected",
                "level": "WARN"
            })

        # Task #3: Planning Guard - Check if operation is allowed in current phase
        # Task #10: Skip check if explicitly requested (but already audited above)
        if not skip_planning_guard:
            # Get task if available (from execution_request)
            task_id = getattr(self, '_current_task_id', None)
            task = None
            if task_id:
                task = self.task_manager.get_task(task_id)

            # Determine operation type and name for planning guard
            operation_type, operation_name = self._classify_operation(action)

            # Check with planning guard
            try:
                self.planning_guard.assert_operation_allowed(
                    operation_type=operation_type,
                    operation_name=operation_name,
                    task=task,
                    mode_id=getattr(self, '_current_mode_id', None),
                    metadata={"action": action, "op_id": op_id}
                )
            except PlanningSideEffectForbiddenError as e:
                # Log the violation and return error result
                self.audit_logger.log_error(
                    f"Planning guard blocked operation: {e.message}"
                )
                return {
                    "operation_id": op_id,
                    "action": action,
                    "status": "forbidden",
                    "error": str(e),
                    "error_type": "PlanningSideEffectForbiddenError"
                }

        self.audit_logger.log_operation_start(op_id, action, params)
        
        try:
            # æ ¹æ® action ç±»å‹æ‰§è¡Œ
            if action == "write_file":
                result = self._execute_write_file(params, worktree_path)
            elif action == "update_file":
                result = self._execute_write_file(params, worktree_path)  # åŒæ ·é€»è¾‘
            elif action == "git_commit":
                result = self._execute_git_commit(params, worktree_path)
            elif action == "git_add":
                result = self._execute_git_add(params, worktree_path)
            elif action == "mkdir":
                result = self._execute_mkdir(params, worktree_path)
            else:
                raise ValueError(f"Unknown action: {action}")
            
            self.audit_logger.log_operation_end(op_id, "success", result)
            
            return {
                "operation_id": op_id,
                "action": action,
                "status": "success",
                "result": result
            }
        
        except Exception as e:
            self.audit_logger.log_operation_end(op_id, "failed", {"error": str(e)})
            
            return {
                "operation_id": op_id,
                "action": action,
                "status": "failed",
                "error": str(e)
            }
    
    def _execute_write_file(self, params: Dict[str, Any], worktree_path: Path) -> Dict[str, Any]:
        """æ‰§è¡Œ write_file æ“ä½œ"""
        path = params["path"]
        content = params["content"]
        
        file_path = worktree_path / path
        file_path.parent.mkdir(parents=True, exist_ok=True)
        file_path.write_text(content)
        
        return {
            "path": str(path),
            "size": len(content),
            "absolute_path": str(file_path)
        }
    
    def _execute_mkdir(self, params: Dict[str, Any], worktree_path: Path) -> Dict[str, Any]:
        """æ‰§è¡Œ mkdir æ“ä½œ"""
        path = params["path"]
        
        dir_path = worktree_path / path
        dir_path.mkdir(parents=True, exist_ok=True)
        
        return {
            "path": str(path),
            "absolute_path": str(dir_path)
        }
    
    def _execute_git_add(self, params: Dict[str, Any], worktree_path: Path) -> Dict[str, Any]:
        """æ‰§è¡Œ git add æ“ä½œ"""
        paths = params.get("paths", ["."])
        
        if isinstance(paths, str):
            paths = [paths]
        
        # ä½¿ç”¨ GitClientï¼ˆä¸ç”¨ subprocessï¼‰
        git_client = GitClientFactory.get_client(worktree_path)
        git_client.add(paths)
        
        return {
            "paths": paths
        }
    
    def _execute_git_commit(self, params: Dict[str, Any], worktree_path: Path) -> Dict[str, Any]:
        """æ‰§è¡Œ git commit æ“ä½œ"""
        message = params["message"]
        
        # ä½¿ç”¨ GitClientï¼ˆä¸ç”¨ subprocessï¼‰
        git_client = GitClientFactory.get_client(worktree_path)
        
        # git add -A (æ·»åŠ æ‰€æœ‰å˜æ›´)
        git_client.add_all()
        
        # git commit
        commit_hash = git_client.commit(message)
        
        return {
            "commit_hash": commit_hash,
            "message": message,
            "short_hash": commit_hash[:8]
        }
    
    def apply_diff_or_raise(
        self,
        diff: str,
        allowed_paths: List[str],
        forbidden_paths: List[str],
        worktree_path: Path,
        audit_context: Optional[str] = None,
        policy_provided: bool = True,  # ğŸ”© ç»ˆå®¡3ï¼šè®°å½• policy æ˜¯å¦æä¾›
        mode_id: Optional[str] = None  # ğŸ”© M3 ç»‘å®šç‚¹ï¼šmode é—¸é—¨
    ) -> Dict[str, Any]:
        """
        ğŸ”© H3-2ï¼šç»Ÿä¸€çš„ apply diff å…¥å£ï¼ˆé˜²æœªæ¥ç»•è¿‡ï¼‰
        ğŸ”© M3 ç»‘å®šç‚¹ï¼šMode å¼ºåˆ¶æ ¡éªŒï¼ˆåªæœ‰ implementation å¯ apply diffï¼‰
        
        è¿™æ˜¯ ONLY åˆæ³•çš„ diff åº”ç”¨å…¥å£ã€‚
        ä»»ä½•è¿›å…¥ "apply diff" çš„è·¯å¾„éƒ½å¿…é¡»ç»è¿‡æ­¤å‡½æ•°ã€‚
        
        ç¡¬è§„åˆ™ï¼š
        1. å¿…é¡»å…ˆé€šè¿‡ Mode æ ¡éªŒï¼ˆåªæœ‰ implementation å…è®¸ï¼‰
        2. å¿…é¡»å…ˆé€šè¿‡ DiffVerifier.verify()
        3. å¦‚æœ is_valid == Falseï¼Œraise DiffRejectedï¼ˆä¸å…è®¸ applyï¼‰
        4. å¦‚æœ is_valid == Trueï¼Œæ‰è°ƒç”¨ GitClient.apply_patch()
        5. æ‰€æœ‰æ“ä½œè®°å½•åˆ° audit_logger
        
        Args:
            diff: Unified diff å†…å®¹
            allowed_paths: å…è®¸ä¿®æ”¹çš„è·¯å¾„ï¼ˆglob æ¨¡å¼ï¼‰
            forbidden_paths: ç¦æ­¢ä¿®æ”¹çš„è·¯å¾„ï¼ˆglob æ¨¡å¼ï¼‰
            worktree_path: worktree è·¯å¾„
            audit_context: å®¡è®¡ä¸Šä¸‹æ–‡ï¼ˆå¦‚ tool_run_idï¼‰
            policy_provided: æ˜¯å¦æä¾›äº† policy
            mode_id: Mode IDï¼ˆå¦‚æœä¸º Noneï¼Œä»å®ä¾‹å˜é‡è¯»å–ï¼‰
        
        Returns:
            {
                "status": "applied" | "rejected",
                "diff_length": int,
                "files_touched": List[str],
                "validation": DiffValidationResult.to_dict()
            }
        
        Raises:
            DiffRejected: å¦‚æœ diff éªŒè¯å¤±è´¥
            ModeViolationError: å¦‚æœ Mode ä¸å…è®¸ apply diff
        """
        from ...ext.tools import DiffVerifier, ToolResult
        
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # INTEGRATOR FREEZE (Agent 4): Diff åº”ç”¨å”¯ä¸€é—¸é—¨
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # æ­¤æ–¹æ³•æ˜¯æ‰€æœ‰ diff åº”ç”¨çš„å”¯ä¸€å…¥å£ï¼Œä»»ä½•ä»£ç å˜æ›´å¿…é¡»ç»è¿‡æ­¤é—¸é—¨ã€‚
        #
        # éªŒæ”¶å‘½ä»¤:
        #   rg "apply_diff_or_raise" agentos | wc -l
        #   æœŸæœ›ç»“æœ: 2ï¼ˆå®šä¹‰ + è°ƒç”¨ï¼‰
        #
        #   rg "GitClient\.apply_patch\(" agentos | wc -l
        #   æœŸæœ›ç»“æœ: 2ï¼ˆå®šä¹‰ + åœ¨æœ¬æ–¹æ³•å†…è°ƒç”¨ï¼‰
        #
        # Mode æ£€æŸ¥ç¡¬çº¦æŸ:
        #   - 100% ä¾èµ– mode.allows_commit()
        #   - é implementation mode å¿…é¡»æŠ›å‡º ModeViolationError
        #   - æ— ä»»ä½•ç‰¹æ®Šè·¯å¾„ / test bypass / legacy hack
        # â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
        # ğŸ”© M3 ç»‘å®šç‚¹ï¼šMode é—¸é—¨
        if mode_id is None:
            mode_id = getattr(self, '_current_mode_id', 'implementation')
        
        try:
            mode = get_mode(mode_id)
        except Exception as e:
            self.audit_logger.log_error(f"Invalid mode_id '{mode_id}': {e}")
            raise ModeViolationError(
                f"Invalid mode_id '{mode_id}': {e}",
                mode_id=mode_id,
                operation="apply_diff",
                error_category="config"
            )
        
        # ğŸ”© M3 ç»‘å®šç‚¹ï¼šåªæœ‰ implementation å…è®¸ apply diff
        if not mode.allows_commit():
            self.audit_logger.log_event("mode_diff_denied", details={
                "mode_id": mode_id,
                "operation": "apply_diff",
                "reason": f"Mode '{mode_id}' does not allow commit/diff operations",
                "context": audit_context or "unknown"
            })

            # ğŸ”” Mode è¿è§„å‘Šè­¦ (Task 27: Emit to EventBus)
            emit_mode_violation(
                mode_id=mode_id,
                operation="apply_diff",
                message=f"Mode '{mode_id}' attempted to apply diff (forbidden)",
                context={
                    "audit_context": audit_context or "unknown",
                    "allows_commit": False,
                    "error_category": "config"
                },
                severity=AlertSeverity.ERROR,
                task_id=None  # Will be extracted from context if available
            )

            raise ModeViolationError(
                f"Mode '{mode_id}' does not allow diff operations. Only 'implementation' mode can apply diffs.",
                mode_id=mode_id,
                operation="apply_diff",
                error_category="config"
            )
        
        # ğŸ”© è¡¥å¼º2ï¼šè®°å½• diff policy scopeï¼ˆå®¡è®¡è¯æ®ï¼‰+ Mode ä¿¡æ¯
        # ğŸ”© è¡¥å¼º2æ”¹è¿›ï¼špattern è„±æ•æˆªæ–­ï¼ˆé˜²æ­¢è¿‡é•¿/æ•æ„Ÿè·¯å¾„ï¼‰+ scope_source æ”¹ä¸º policy_provided
        # ğŸ”© ç»ˆå®¡3ï¼šå¢åŠ  policy_provided å’Œ policy_paths_empty å­—æ®µï¼ˆé˜²æ­¢è¯¯è§£ï¼‰
        
        # è„±æ•å¤„ç†ï¼šæ¯æ¡ pattern æœ€å¤š 120 chars
        # ğŸ”© ç»ˆå®¡4ï¼šé˜²æ­¢ None / é string patternï¼ˆè„æ•°æ®ï¼‰
        def sanitize_pattern(pattern: str) -> str:
            if pattern is None:
                return ""
            pattern = str(pattern)  # å¼ºåˆ¶è½¬ä¸º string
            return pattern[:120] if len(pattern) <= 120 else pattern[:117] + "..."
        
        self.audit_logger.log_event("diff_policy_scope", details={
            "context": audit_context or "unknown",
            "mode_id": mode_id,  # ğŸ”© M3ï¼šè®°å½• mode_id
            "policy_provided": policy_provided,  # ğŸ”© ç»ˆå®¡3ï¼šæ˜ç¡® policy æ˜¯å¦æä¾›
            "policy_paths_empty": len(allowed_paths) == 0,  # ğŸ”© ç»ˆå®¡3ï¼šæ˜ç¡® paths æ˜¯å¦ä¸ºç©º
            "allowed_paths_count": len(allowed_paths),
            "forbidden_paths_count": len(forbidden_paths),
            "allowed_paths_sample": [sanitize_pattern(p) for p in allowed_paths[:3]] if allowed_paths else [],  # å‰3ä¸ªpatternï¼Œè„±æ•
            "forbidden_paths_sample": [sanitize_pattern(p) for p in forbidden_paths[:3]] if forbidden_paths else [],
            "scope_source": "policy" if policy_provided else "none"  # ğŸ”© ç»ˆå®¡3ï¼šæ ¹æ® policy_provided è®¾ç½®
        })
        
        # ğŸ”© H3-2ï¼šå¼ºåˆ¶éªŒè¯ï¼ˆä¸å…è®¸ç»•è¿‡ï¼‰
        # åˆ›å»ºä¸´æ—¶ ToolResult ç”¨äºéªŒè¯
        temp_result = ToolResult(
            tool="executor-internal",
            status="success",
            diff=diff,
            files_touched=[],  # DiffVerifier ä¼šä» diff ä¸­æå–
            line_count=len(diff.split('\n')),
            tool_run_id=audit_context or "unknown"
        )
        
        diff_verifier = DiffVerifier()
        validation = diff_verifier.verify(temp_result, allowed_paths, forbidden_paths)
        
        # å®¡è®¡ï¼šè®°å½•éªŒè¯ç»“æœ
        self.audit_logger.log_event("diff_validation", details={
            "context": audit_context or "unknown",
            "is_valid": validation.is_valid,
            "errors_count": len(validation.errors),
            "warnings_count": len(validation.warnings),
            "errors": validation.errors,
            "warnings": validation.warnings
        })
        
        # ğŸ”© H3-2ï¼šå¦‚æœéªŒè¯å¤±è´¥ï¼Œraiseï¼ˆä¸å…è®¸ applyï¼‰
        if not validation.is_valid:
            error_msg = f"Diff verification failed: {validation.errors}"
            self.audit_logger.log_error(error_msg)
            
            raise DiffRejected(
                reason=error_msg,
                validation=validation
            )
        
        # éªŒè¯é€šè¿‡ï¼Œapply diff
        # å†™å…¥ä¸´æ—¶ patch æ–‡ä»¶
        import tempfile
        with tempfile.NamedTemporaryFile(mode='w', suffix='.patch', delete=False) as f:
            f.write(diff)
            patch_file = Path(f.name)
        
        try:
            # ä½¿ç”¨ GitClient apply_patch
            git_client = GitClientFactory.get_client(worktree_path)
            git_client.apply_patch(patch_file)
            
            # å®¡è®¡ï¼šè®°å½•æˆåŠŸ
            self.audit_logger.log_event("diff_applied", details={
                "context": audit_context or "unknown",
                "diff_length": len(diff),
                "files_touched": temp_result.files_touched,
                "validation": validation.to_dict()
            })
            
            return {
                "status": "applied",
                "diff_length": len(diff),
                "files_touched": temp_result.files_touched,
                "validation": validation.to_dict()
            }
            
        finally:
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            patch_file.unlink(missing_ok=True)
    
    def _bring_back_commits_from_worktree(
        self,
        worktree_path: Path,
        base_commit: str,
        rollback_point: dict,
        run_dir: Path,
        exec_req_id: str,
        policy: Optional[Any] = None
    ) -> tuple[int, int]:
        """
        P0-RT3 + é’‰å­2: å°† worktree çš„ commits å¸¦å›ä¸» repoï¼ˆå¼ºåˆ¶æ‰§è¡Œï¼Œç”Ÿæˆè‡ªè¯è¯æ®ï¼‰
        
        ğŸ”© H3-2 æ”¶å£2ï¼šallowed_paths ä» policy è·å–ï¼ˆä¸ç”¨ ["*"]ï¼‰
        
        ä½¿ç”¨ format-patch â†’ am çš„æ–¹å¼ï¼Œç¡®ä¿ä¸» repo è·å¾—æ‰€æœ‰ commits
        
        Args:
            worktree_path: worktree è·¯å¾„
            base_commit: åŸºç¡€ commit SHA
            rollback_point: å›æ»šç‚¹ï¼ˆåŒ…å« base commitï¼‰
            run_dir: è¿è¡Œç›®å½•
            exec_req_id: æ‰§è¡Œè¯·æ±‚ ID
            policy: SandboxPolicy å¯¹è±¡ï¼ˆç”¨äºè·å– allowed_pathsï¼‰
        
        Returns:
            (commits_brought_back, patches_generated)
        """
        try:
            # 1. åœ¨ worktree æ”¶é›† commitsï¼ˆé’‰å­2: éœ€è¦è®°å½•æ‰€æœ‰ commit SHAsï¼‰
            worktree_git = GitClientFactory.get_client(worktree_path)
            head_sha = worktree_git.get_head_sha()
            
            # è·å– worktree ä¸­ä» base_commit åˆ° HEAD çš„æ‰€æœ‰ commits
            worktree_commits = worktree_git.get_commit_range(base_commit, head_sha)
            
            # P0-RT3: ç”Ÿæˆç‹¬ç«‹çš„ patch æ–‡ä»¶ï¼ˆæ¯ä¸ª commit ä¸€ä¸ªï¼‰
            patches_dir = run_dir / "patches"
            patches_dir.mkdir(parents=True, exist_ok=True)
            
            # ä½¿ç”¨ format-patch ç”Ÿæˆå¤šä¸ª patch æ–‡ä»¶
            patch_files = worktree_git.format_patch_multiple(base_commit, head_sha, patches_dir)
            
            # é’‰å­2: è®¡ç®—æ¯ä¸ª patch çš„ SHA256
            patch_sha256 = {}
            for patch_file in patch_files:
                with open(patch_file, "rb") as f:
                    patch_sha256[patch_file.name] = hashlib.sha256(f.read()).hexdigest()
            
            self.audit_logger.log_event("patches_generated", details={
                "base_sha": base_commit[:8],
                "head_sha": head_sha[:8],
                "patch_count": len(patch_files),
                "patches_dir": str(patches_dir)
            })
            
            # 2. å›åˆ°ä¸» repo åº”ç”¨æ‰€æœ‰ patches
            main_git = GitClientFactory.get_client(self.repo_path)
            
            # è®°å½•åº”ç”¨å‰çš„ HEADï¼ˆç”¨äºè®¡ç®—æ–° commitsï¼‰
            before_am_head = main_git.get_head_sha()
            
            # ğŸ”© H3-2ï¼šæ‰€æœ‰ patch apply å¿…é¡»ç»è¿‡ç»Ÿä¸€å…¥å£
            # ğŸ”© H3-2 æ”¶å£2ï¼šallowed_paths ä» policy è·å–ï¼ˆä¸ç”¨ ["*"]ï¼‰
            # ğŸ”© è¡¥å¼º3ï¼šæ—  policy æ—¶æ˜¾å¼æ‹’ç»ï¼ˆé˜²æ­¢ç»•è¿‡ï¼‰
            
            # ä» policy è·å–å…è®¸çš„è·¯å¾„ï¼Œå¦‚æœæ²¡æœ‰ policyï¼Œåˆ™æ‹’ç»ï¼ˆå®‰å…¨ç­–ç•¥ï¼‰
            if policy:
                # ğŸ”¥ å¤§å‘ä¿®å¤ï¼špolicy.allowlist å¯èƒ½æ˜¯ pydantic æ¨¡å‹/dataclassï¼Œä¸æ˜¯ dict
                # ğŸ”© ç»ˆå®¡5ï¼šå¢å¼º dataclass æ”¯æŒï¼ˆç”¨ __dict__ æˆ– vars()ï¼‰
                allowlist_obj = policy.allowlist
                if hasattr(allowlist_obj, "dict"):
                    # pydantic v1
                    allowlist_dict = allowlist_obj.dict()
                elif hasattr(allowlist_obj, "model_dump"):
                    # pydantic v2
                    allowlist_dict = allowlist_obj.model_dump()
                elif not isinstance(allowlist_obj, dict):
                    # dataclass or other
                    try:
                        # ğŸ”© ç»ˆå®¡5ï¼šä¼˜å…ˆç”¨ __dict__ï¼ˆdataclass å‹å¥½ï¼‰
                        if hasattr(allowlist_obj, "__dict__"):
                            allowlist_dict = allowlist_obj.__dict__
                        else:
                            allowlist_dict = dict(allowlist_obj)
                    except (TypeError, ValueError):
                        # æœ€åé˜²çº¿ï¼šå½“ä½œ schema_mismatch
                        error_msg = f"Policy.allowlist is not a dict-like object: {type(allowlist_obj)}"
                        self.audit_logger.log_event("bring_back_policy_schema_error", details={
                            "error": error_msg,
                            "error_category": "schema",
                            "allowlist_type": str(type(allowlist_obj))
                        })
                        raise PolicyDeniedError(
                            message=error_msg,
                            operation="bring_back_commits",
                            reason="Policy.allowlist schema mismatch (error_category: schema)",
                            rule_id="executor:bring_back_allowlist_schema"
                        )
                else:
                    # å·²ç»æ˜¯ dict
                    allowlist_dict = allowlist_obj
                
                allowed_paths = allowlist_dict.get("paths", [])
                forbidden_paths = allowlist_dict.get("forbidden_paths", [])
            else:
                # ğŸ”© è¡¥å¼º3ï¼šæ—  policy æ—¶æ˜¾å¼ raiseï¼ˆæ¯” allowed_paths=[] æ›´å¯è¿ç»´ï¼‰
                # ğŸ”© è¡¥å¼º3æ”¹è¿›ï¼šerror_category æ˜ç¡®ä¸º configï¼ˆä¸æ˜¯"æ‹’ç»"è€Œæ˜¯"ç¼ºå¤±é…ç½®"ï¼‰
                error_msg = "Policy is required for bring-back commits verification. Cannot apply patches without policy-defined allowlist."
                self.audit_logger.log_event("bring_back_policy_missing", details={
                    "error": error_msg,
                    "error_category": "config",  # ğŸ”© è¡¥å¼º3æ”¹è¿›ï¼šæ˜ç¡®å½’ç±»ä¸º config
                    "exec_req_id": exec_req_id,
                    "patches_count": len(patch_files)
                })
                raise PolicyDeniedError(
                    message=error_msg,
                    operation="bring_back_commits",
                    reason="Policy missing: bring-back requires policy.allowlist.paths for diff verification (error_category: config)",
                    rule_id="executor:bring_back_requires_policy"
                )
            
            for patch_file in patch_files:
                # è¯»å– patch å†…å®¹å¹¶é€šè¿‡ apply_diff_or_raise() éªŒè¯
                patch_content = patch_file.read_text()
                self.apply_diff_or_raise(
                    diff=patch_content,
                    allowed_paths=allowed_paths,  # ğŸ”© H3-2 æ”¶å£2ï¼šä» policy è·å–
                    forbidden_paths=forbidden_paths,
                    worktree_path=self.repo_path,
                    audit_context=f"bring_back_patch_{patch_file.name}",
                    policy_provided=True  # ğŸ”© ç»ˆå®¡3ï¼špolicy å·²æä¾›
                )
            
            # 3. éªŒè¯ commits æ•°é‡
            main_head = main_git.get_head_sha()
            
            # é’‰å­2: è·å–ä¸» repo åº”ç”¨ patch åæ–°å¢çš„ commits
            main_repo_commits_after_am = main_git.get_commit_range(before_am_head, main_head)
            
            self.audit_logger.log_event("commits_brought_back", details={
                "worktree_head": head_sha[:8],
                "main_repo_head": main_head[:8],
                "commits_count": len(patch_files),
                "patches_applied": len(patch_files)
            })
            
            # 4. P0-RT3 + é’‰å­2: ç”Ÿæˆ sandbox_proof.jsonï¼ˆè‡ªè¯èƒ½åŠ›å¢å¼ºï¼‰
            sandbox_proof = {
                "worktree_path": str(worktree_path),
                "base_commit": base_commit,
                "worktree_head_sha": head_sha,
                "main_repo_head_sha": main_head,
                "patch_count": len(patch_files),
                "patch_files": [str(p.name) for p in patch_files],
                # é’‰å­2: è‡ªè¯å­—æ®µ
                "worktree_commits": worktree_commits,
                "main_repo_commits_after_am": main_repo_commits_after_am,
                "patch_sha256": patch_sha256,
                "brought_back_at": utc_now_iso()
            }
            
            proof_file = run_dir / "audit" / "sandbox_proof.json"
            proof_file.parent.mkdir(parents=True, exist_ok=True)
            with open(proof_file, "w", encoding="utf-8") as f:
                json.dump(sandbox_proof, f, indent=2)
            
            return len(patch_files), len(patch_files)
        
        except Exception as e:
            self.audit_logger.log_error(f"Failed to bring back commits: {str(e)}")
            return 0, 0
    
    def _create_error_result(
        self,
        exec_req_id: str,
        status: str,
        error: str,
        run_tape: RunTape,
        run_dir: Path
    ) -> Dict[str, Any]:
        """
        åˆ›å»ºé”™è¯¯ç»“æœï¼ˆç»Ÿä¸€é”™è¯¯è¿”å›æ ¼å¼ï¼‰
        
        Args:
            exec_req_id: æ‰§è¡Œè¯·æ±‚ ID
            status: çŠ¶æ€ï¼ˆfailed/blocked/deniedï¼‰
            error: é”™è¯¯æ¶ˆæ¯
            run_tape: RunTape å®ä¾‹
            run_dir: è¿è¡Œç›®å½•
        
        Returns:
            æ‰§è¡Œç»“æœå­—å…¸
        """
        started_at = utc_now_iso()
        completed_at = started_at
        
        # P0-RT2: ç”Ÿæˆ execution_summary.jsonï¼ˆå³ä½¿å¤±è´¥ï¼‰
        self._generate_execution_summary(
            run_dir,
            exec_req_id,
            status,
            0,
            0,
            started_at,
            completed_at,
            error=error
        )
        
        # P0-RT2: ç”Ÿæˆ checksums.jsonï¼ˆå³ä½¿å¤±è´¥ï¼‰
        audit_dir = run_dir / "audit"
        self._generate_checksums(audit_dir, run_tape)
        
        return {
            "execution_result_id": f"exec_result_{exec_req_id}",
            "schema_version": "0.11.1",
            "execution_request_id": exec_req_id,
            "status": status,
            "error": error,
            "started_at": started_at,
            "completed_at": completed_at
        }
    
    def _generate_execution_summary(
        self,
        run_dir: Path,
        exec_req_id: str,
        status: str,
        commit_count: int,
        patch_count: int,
        started_at: str,
        completed_at: str,
        error: Optional[str] = None
    ) -> None:
        """
        P0-RT2: ç”Ÿæˆ execution_summary.jsonï¼ˆR3 è¦æ±‚ï¼‰
        
        Args:
            run_dir: è¿è¡Œç›®å½•
            exec_req_id: æ‰§è¡Œè¯·æ±‚ ID
            status: çŠ¶æ€
            commit_count: Commit æ•°é‡
            patch_count: Patch æ•°é‡
            started_at: å¼€å§‹æ—¶é—´
            completed_at: å®Œæˆæ—¶é—´
            error: é”™è¯¯æ¶ˆæ¯ï¼ˆå¯é€‰ï¼‰
        """
        reports_dir = run_dir / "reports"
        reports_dir.mkdir(parents=True, exist_ok=True)
        
        summary = {
            "execution_request_id": exec_req_id,
            "status": status,
            "commit_count": commit_count,
            "patch_count": patch_count,
            "sandbox_used": True,  # å¼ºåˆ¶ä½¿ç”¨ worktree
            "started_at": started_at,
            "completed_at": completed_at
        }
        
        if error:
            summary["error"] = error
        
        summary_file = reports_dir / "execution_summary.json"
        with open(summary_file, "w", encoding="utf-8") as f:
            json.dump(summary, f, indent=2)
    
    def _generate_checksums(
        self,
        audit_dir: Path,
        run_tape: RunTape
    ) -> None:
        """
        P0-RT2: ç”Ÿæˆ checksums.jsonï¼ˆR3 è¦æ±‚ï¼‰
        
        Args:
            audit_dir: å®¡è®¡ç›®å½•
            run_tape: RunTape å®ä¾‹
        """
        checksums = {
            "generated_at": utc_now_iso(),
            "files": {}
        }
        
        # æ·»åŠ  run_tape è‡ªèº«çš„ checksum
        if run_tape.run_tape_path.exists():
            content = run_tape.run_tape_path.read_bytes()
            checksums["files"]["run_tape.jsonl"] = hashlib.sha256(content).hexdigest()
        
        # æ·»åŠ  execution_request.json çš„ checksumï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        request_file = audit_dir.parent / "execution_request.json"
        if request_file.exists():
            content = request_file.read_bytes()
            checksums["files"]["execution_request.json"] = hashlib.sha256(content).hexdigest()
        
        checksums_file = audit_dir / "checksums.json"
        with open(checksums_file, "w", encoding="utf-8") as f:
            json.dump(checksums, f, indent=2)

    def _classify_operation(self, action: str) -> tuple[str, str]:
        """
        Classify operation into (operation_type, operation_name) for planning guard

        Task #3: Planning Guard operation classification

        Args:
            action: Operation action (write_file, git_commit, etc.)

        Returns:
            Tuple of (operation_type, operation_name)
        """
        # Map executor actions to planning guard operation types
        if action in ["write_file", "update_file"]:
            return ("file_write", "file.write")
        elif action == "mkdir":
            return ("file_write", "Path.mkdir")
        elif action in ["git_commit"]:
            return ("git", "git.commit")
        elif action == "git_add":
            return ("git", "git.add")
        elif action == "git_push":
            return ("git", "git.push")
        elif action in ["run_command", "exec", "shell"]:
            return ("shell", "subprocess.run")
        else:
            # Unknown action, classify as generic
            return ("unknown", action)

# AgentOS Voice STT Module

æœ¬åœ° Whisper è¯­éŸ³è½¬æ–‡æœ¬ (STT) å’Œè¯­éŸ³æ´»åŠ¨æ£€æµ‹ (VAD) æ¨¡å—ã€‚

## æ¦‚è¿°

è¯¥æ¨¡å—æä¾›äº†åŸºäºæœ¬åœ° Whisper æ¨¡å‹çš„è¯­éŸ³è½¬æ–‡æœ¬åŠŸèƒ½ï¼Œä»¥åŠåŸºäº WebRTC VAD çš„è¯­éŸ³æ´»åŠ¨æ£€æµ‹åŠŸèƒ½ã€‚

### æ ¸å¿ƒç»„ä»¶

1. **ISTTProvider** (`base.py`): STT æä¾›è€…æŠ½è±¡æ¥å£
2. **WhisperLocalSTT** (`whisper_local.py`): åŸºäº faster-whisper çš„æœ¬åœ° Whisper å®ç°
3. **VADDetector** (`vad.py`): åŸºäº webrtcvad çš„è¯­éŸ³æ´»åŠ¨æ£€æµ‹

## å®‰è£…ä¾èµ–

ä¾èµ–å·²æ·»åŠ åˆ° `pyproject.toml` ä¸­ï¼š

```toml
"faster-whisper>=1.0.0",  # Local Whisper STT for voice communication
"webrtcvad>=2.0.10",      # Voice Activity Detection (VAD)
"numpy>=1.24.0",          # Required for audio processing
```

å®‰è£…ä¾èµ–ï¼š

```bash
pip install -e .
# æˆ–è€…å•ç‹¬å®‰è£…
pip install faster-whisper>=1.0.0 webrtcvad>=2.0.10 numpy>=1.24.0
```

## ä½¿ç”¨ç¤ºä¾‹

### åŸºæœ¬ä½¿ç”¨

```python
import asyncio
import numpy as np
from agentos.core.communication.voice.stt import WhisperLocalSTT, VADDetector

async def main():
    # åˆ›å»º STT å®ä¾‹
    stt = WhisperLocalSTT(
        model_name="base",    # tiny/base/small/medium/large
        device="cpu",         # cpu/cuda/auto
        language=None         # None è¡¨ç¤ºè‡ªåŠ¨æ£€æµ‹ï¼Œæˆ–æŒ‡å®šå¦‚ "zh"/"en"
    )

    # è½¬å½•éŸ³é¢‘ (å‡è®¾ audio_bytes æ˜¯ 16kHz int16 PCM æ ¼å¼)
    text = await stt.transcribe_audio(audio_bytes, sample_rate=16000)
    print(f"Transcription: {text}")

    # åˆ›å»º VAD å®ä¾‹
    vad = VADDetector(aggressiveness=2)  # 0-3, è¶Šå¤§è¶Šä¸¥æ ¼

    # æ£€æµ‹è¯­éŸ³ (audio_chunk å¿…é¡»æ˜¯ 10/20/30ms çš„éŸ³é¢‘å¸§)
    is_speech = vad.is_speech(audio_chunk, sample_rate=16000)
    print(f"Is speech: {is_speech}")

asyncio.run(main())
```

### ä½¿ç”¨ VoiceServiceï¼ˆæ¨èï¼‰

```python
from agentos.core.communication.voice.service import VoiceService

# åˆ›å»ºæœåŠ¡å®ä¾‹ï¼ˆè‡ªåŠ¨ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®ï¼‰
service = VoiceService()

# æˆ–è€…æ˜¾å¼æŒ‡å®šé…ç½®
service = VoiceService(
    stt_model="base",
    stt_device="cpu",
    stt_language="zh",
    vad_aggressiveness=2
)

# è½¬å½•éŸ³é¢‘
text = await service.transcribe_audio(audio_bytes)

# æ£€æµ‹è¯­éŸ³
is_speech = service.is_speech(audio_chunk)
```

### ç¯å¢ƒå˜é‡é…ç½®

VoiceService æ”¯æŒä»¥ä¸‹ç¯å¢ƒå˜é‡ï¼š

```bash
export VOICE_STT_MODEL=base              # Whisper æ¨¡å‹åç§° (é»˜è®¤: base)
export VOICE_STT_DEVICE=cpu              # æ¨ç†è®¾å¤‡ (é»˜è®¤: cpu)
export VOICE_STT_LANGUAGE=zh             # ç›®æ ‡è¯­è¨€ (é»˜è®¤: None, è‡ªåŠ¨æ£€æµ‹)
export VOICE_VAD_AGGRESSIVENESS=2        # VAD ä¸¥æ ¼ç¨‹åº¦ 0-3 (é»˜è®¤: 2)
```

## æ¶æ„è®¾è®¡

### 1. ISTTProvider æ¥å£

å®šä¹‰äº†æ‰€æœ‰ STT æä¾›è€…å¿…é¡»å®ç°çš„æ¥å£ï¼š

```python
class ISTTProvider(ABC):
    async def transcribe_audio(self, audio_bytes: bytes, sample_rate: int = 16000) -> str:
        """è½¬å½•éŸ³é¢‘å­—èŠ‚ä¸ºæ–‡æœ¬"""
        pass

    async def transcribe_stream(self, audio_stream: AsyncIterator[bytes]) -> AsyncIterator[str]:
        """æµå¼è½¬å½•éŸ³é¢‘"""
        pass
```

### 2. WhisperLocalSTT å®ç°

**æ ¸å¿ƒç‰¹æ€§ï¼š**

- **æ‡’åŠ è½½æ¨¡å‹**ï¼šé¦–æ¬¡è°ƒç”¨æ—¶æ‰åŠ è½½æ¨¡å‹ï¼Œé¿å…å¯åŠ¨å»¶è¿Ÿ
- **çº¿ç¨‹æ± æ‰§è¡Œ**ï¼šåœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œ Whisper æ¨ç†ï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯
- **å¤šæ¨¡å‹æ”¯æŒ**ï¼šæ”¯æŒ tiny/base/small/medium/large æ¨¡å‹
- **è®¾å¤‡é€‰æ‹©**ï¼šæ”¯æŒ cpu/cuda/auto
- **è¯­è¨€æ£€æµ‹**ï¼šè‡ªåŠ¨æ£€æµ‹è¯­è¨€æˆ–æŒ‡å®šç›®æ ‡è¯­è¨€
- **å†…ç½® VAD**ï¼šä½¿ç”¨ Whisper å†…ç½®çš„ VAD è¿‡æ»¤
- **é”™è¯¯å¤„ç†**ï¼šå®Œå–„çš„å¼‚å¸¸å¤„ç†å’Œæ—¥å¿—è®°å½•

**éŸ³é¢‘æ ¼å¼è¦æ±‚ï¼š**

- æ ¼å¼ï¼šPCM int16
- é‡‡æ ·ç‡ï¼š16kHzï¼ˆæ¨èï¼‰
- å£°é“ï¼šå•å£°é“

**å®ç°ç»†èŠ‚ï¼š**

```python
# éŸ³é¢‘å­—èŠ‚ â†’ numpy array (float32, [-1, 1])
audio_int16 = np.frombuffer(audio_bytes, dtype=np.int16)
audio_float32 = audio_int16.astype(np.float32) / 32768.0

# åœ¨çº¿ç¨‹æ± ä¸­è¿è¡Œæ¨ç†
segments, info = await loop.run_in_executor(
    None,
    lambda: self._model.transcribe(audio_array, language=self.language)
)
```

### 3. VADDetector å®ç°

**æ ¸å¿ƒç‰¹æ€§ï¼š**

- **è¯­éŸ³æ£€æµ‹**ï¼šæ£€æµ‹éŸ³é¢‘å¸§æ˜¯å¦åŒ…å«è¯­éŸ³
- **é™éŸ³æ£€æµ‹**ï¼šæ£€æµ‹è¿ç»­é™éŸ³ï¼ˆç”¨äºå¥å­è¾¹ç•Œæ£€æµ‹ï¼‰
- **å¯é…ç½®ä¸¥æ ¼ç¨‹åº¦**ï¼š0-3ï¼Œæ•°å€¼è¶Šå¤§è¶Šä¸¥æ ¼ï¼ˆè¶Šä¸å®¹æ˜“æ£€æµ‹åˆ°è¯­éŸ³ï¼‰

**éŸ³é¢‘æ ¼å¼è¦æ±‚ï¼š**

- æ ¼å¼ï¼šPCM int16
- é‡‡æ ·ç‡ï¼š8kHz/16kHz/32kHz
- å¸§é•¿åº¦ï¼š10ms/20ms/30ms

**ä½¿ç”¨ç¤ºä¾‹ï¼š**

```python
vad = VADDetector(aggressiveness=2)

# æ£€æµ‹å•å¸§æ˜¯å¦ä¸ºè¯­éŸ³
# 16kHz, 20ms = 320 samples = 640 bytes
frame_bytes = audio[0:640]
is_speech = vad.is_speech(frame_bytes, sample_rate=16000)

# æ£€æµ‹è¿ç»­é™éŸ³ï¼ˆå¥å­ç»“æŸæ£€æµ‹ï¼‰
buffer = [frame1, frame2, frame3, ...]  # å¤šä¸ªéŸ³é¢‘å¸§
silence_end = vad.detect_silence_end(
    buffer,
    sample_rate=16000,
    threshold_ms=500  # è¿ç»­ 500ms é™éŸ³
)
```

## æµ‹è¯•

### æ‰‹åŠ¨æµ‹è¯•

è¿è¡Œæ‰‹åŠ¨æµ‹è¯•è„šæœ¬ï¼š

```bash
python -m tests.manual.test_whisper_local
```

è¯¥è„šæœ¬ä¼šæµ‹è¯•ï¼š
1. æ¨¡å—å¯¼å…¥
2. VADDetector åŸºæœ¬åŠŸèƒ½
3. WhisperLocalSTT åŸºæœ¬åŠŸèƒ½ï¼ˆä½¿ç”¨åˆæˆé™éŸ³éŸ³é¢‘ï¼‰
4. VoiceService é›†æˆ

**æ³¨æ„**ï¼šé¦–æ¬¡è¿è¡Œæ—¶ä¼šä¸‹è½½ Whisper æ¨¡å‹ï¼ˆbase æ¨¡å‹çº¦ 140MBï¼‰ï¼Œè¯·ç¡®ä¿ç½‘ç»œè¿æ¥æ­£å¸¸ã€‚

### é¢„æœŸè¾“å‡º

```
Testing module imports
âœ“ Successfully imported ISTTProvider
âœ“ Successfully imported WhisperLocalSTT
âœ“ Successfully imported VADDetector
âœ“ All imports PASSED

Testing VADDetector
âœ“ VADDetector instance created successfully
âœ“ is_speech() result: False
âœ“ Silence correctly detected as non-speech
âœ“ VADDetector test PASSED

Testing WhisperLocalSTT
âœ“ WhisperLocalSTT instance created successfully
Starting transcription (this will download model on first run)...
âœ“ Transcription completed: ''
âœ“ Empty result is expected for silence audio
âœ“ WhisperLocalSTT test PASSED

Testing VoiceService
âœ“ VoiceService instance created successfully
âœ“ transcribe_audio() completed: ''
âœ“ is_speech() completed: False
âœ“ VoiceService test PASSED

ğŸ‰ ALL TESTS PASSED
```

## æ€§èƒ½ä¼˜åŒ–å»ºè®®

### 1. æ¨¡å‹é€‰æ‹©

| æ¨¡å‹ | å¤§å° | é€Ÿåº¦ | å‡†ç¡®åº¦ | é€‚ç”¨åœºæ™¯ |
|------|------|------|--------|----------|
| tiny | ~40MB | æœ€å¿« | è¾ƒä½ | åŸå‹å¼€å‘ã€æµ‹è¯• |
| base | ~140MB | å¿« | è‰¯å¥½ | ç”Ÿäº§ç¯å¢ƒï¼ˆæ¨èï¼‰ |
| small | ~460MB | ä¸­ç­‰ | è¾ƒå¥½ | é«˜å‡†ç¡®åº¦éœ€æ±‚ |
| medium | ~1.5GB | æ…¢ | å¾ˆå¥½ | ç¦»çº¿è½¬å½• |
| large | ~3GB | å¾ˆæ…¢ | æœ€å¥½ | ç¦»çº¿æ‰¹é‡å¤„ç† |

### 2. è®¾å¤‡é€‰æ‹©

- **CPU**: é€‚ç”¨äºä½å¹¶å‘åœºæ™¯ï¼Œæ— éœ€ GPU ä¾èµ–
- **CUDA**: é€‚ç”¨äºé«˜å¹¶å‘åœºæ™¯ï¼Œéœ€è¦ NVIDIA GPU å’Œ CUDA
- **auto**: è‡ªåŠ¨æ£€æµ‹ï¼Œä¼˜å…ˆä½¿ç”¨ GPU

### 3. VAD ä¸¥æ ¼ç¨‹åº¦

- **0**: æœ€å®½æ¾ï¼Œå‡ ä¹æ‰€æœ‰å£°éŸ³éƒ½è¢«æ£€æµ‹ä¸ºè¯­éŸ³ï¼ˆé€‚ç”¨äºå˜ˆæ‚ç¯å¢ƒï¼‰
- **1**: å®½æ¾
- **2**: å¹³è¡¡ï¼ˆæ¨èï¼‰
- **3**: æœ€ä¸¥æ ¼ï¼Œåªæ£€æµ‹æ˜ç¡®çš„è¯­éŸ³ï¼ˆé€‚ç”¨äºå®‰é™ç¯å¢ƒï¼‰

## æ•…éšœæ’æŸ¥

### é—®é¢˜ 1: ModuleNotFoundError: No module named 'faster_whisper'

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
pip install faster-whisper>=1.0.0
```

### é—®é¢˜ 2: ModuleNotFoundError: No module named 'webrtcvad'

**è§£å†³æ–¹æ¡ˆ**ï¼š
```bash
pip install webrtcvad>=2.0.10
```

### é—®é¢˜ 3: é¦–æ¬¡è¿è¡Œå¾ˆæ…¢

**åŸå› **ï¼šé¦–æ¬¡è¿è¡Œéœ€è¦ä¸‹è½½ Whisper æ¨¡å‹ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼šè€å¿ƒç­‰å¾…ï¼Œæ¨¡å‹ä¼šè¢«ç¼“å­˜åˆ° `~/.cache/huggingface/`ã€‚

### é—®é¢˜ 4: ValueError: Audio chunk must be 10, 20, or 30 ms

**åŸå› **ï¼šVAD è¦æ±‚éŸ³é¢‘å¸§é•¿åº¦å¿…é¡»æ˜¯ 10/20/30msã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼šç¡®ä¿éŸ³é¢‘å¸§é•¿åº¦æ­£ç¡®ã€‚ä¾‹å¦‚ï¼š
- 16kHz, 20ms = 320 samples = 640 bytes

### é—®é¢˜ 5: CUDA out of memory

**åŸå› **ï¼šGPU å†…å­˜ä¸è¶³ã€‚

**è§£å†³æ–¹æ¡ˆ**ï¼š
1. ä½¿ç”¨æ›´å°çš„æ¨¡å‹ï¼ˆå¦‚ base æˆ– tinyï¼‰
2. åˆ‡æ¢åˆ° CPU: `device="cpu"`
3. é™ä½æ‰¹å¤„ç†å¤§å°

## æœªæ¥æ‰©å±•

### è®¡åˆ’ä¸­çš„åŠŸèƒ½

1. **å®æ—¶æµå¼è½¬å½•**ï¼šæ”¹è¿› `transcribe_stream()` å®ç°ï¼Œæ”¯æŒçœŸæ­£çš„å®æ—¶è½¬å½•
2. **å¤šè¯­è¨€æ··åˆæ£€æµ‹**ï¼šè‡ªåŠ¨æ£€æµ‹å’Œåˆ‡æ¢å¤šç§è¯­è¨€
3. **è‡ªå®šä¹‰è¯æ±‡è¡¨**ï¼šæ”¯æŒä¸“ä¸šæœ¯è¯­å’Œäººåçš„ä¼˜å…ˆè¯†åˆ«
4. **è¯´è¯äººåˆ†ç¦»**ï¼šåŒºåˆ†ä¸åŒè¯´è¯äºº
5. **æ ‡ç‚¹ç¬¦å·æ¢å¤**ï¼šè‡ªåŠ¨æ·»åŠ æ ‡ç‚¹ç¬¦å·

### æ›¿ä»£ STT æä¾›è€…

å¯ä»¥å®ç°å…¶ä»– STT æä¾›è€…ï¼ˆåªéœ€ç»§æ‰¿ `ISTTProvider`ï¼‰ï¼š

- **WhisperAPI**: ä½¿ç”¨ OpenAI Whisper API
- **GoogleSTT**: ä½¿ç”¨ Google Cloud Speech-to-Text
- **AzureSTT**: ä½¿ç”¨ Azure Cognitive Services
- **DeepSpeech**: ä½¿ç”¨ Mozilla DeepSpeech

## å‚è€ƒèµ„æ–™

- [faster-whisper GitHub](https://github.com/guillaumekln/faster-whisper)
- [OpenAI Whisper](https://github.com/openai/whisper)
- [webrtcvad GitHub](https://github.com/wiseman/py-webrtcvad)
- [WebRTC VAD Documentation](https://webrtc.org/getting-started/overview)

## è®¸å¯è¯

MIT License - ä¸ AgentOS ä¸»é¡¹ç›®ä¿æŒä¸€è‡´

"""
LM Studio Adapter - LM Studio æœ¬åœ°æ¨¡å‹é€‚é…å™¨

Step 4 æ‰©å±•ï¼š
- ç»§æ‰¿ OpenAIChatAdapterï¼ˆå¤ç”¨ OpenAI-compatible æ¥å£ï¼‰
- health_check(): æ£€æŸ¥ LM Studio æœåŠ¡ + æ¨¡å‹æ˜¯å¦åŠ è½½
- run(): é€šè¿‡ OpenAI-compatible API è°ƒç”¨
- supports(): å£°æ˜ local æ¨¡å¼èƒ½åŠ›

LM Studio é…ç½®ï¼š
- Base URL: http://localhost:1234/v1
- Models endpoint: /models
- ä¸å¼ºåˆ¶ API keyï¼ˆä½¿ç”¨å ä½ç¬¦ "lm-studio"ï¼‰
"""

import os
from pathlib import Path
from typing import Optional

# requests æ˜¯å¯é€‰ä¾èµ–
try:
    import requests
    HAS_REQUESTS = True
except ImportError:
    HAS_REQUESTS = False
    requests = None

from .openai_chat_adapter import OpenAIChatAdapter
from .types import ToolHealth, ToolCapabilities


class LMStudioAdapter(OpenAIChatAdapter):
    """LM Studio æœ¬åœ°æ¨¡å‹é€‚é…å™¨"""
    
    def __init__(self, model_id: str = "local-model", base_url: str = "http://localhost:1234/v1"):
        """
        åˆå§‹åŒ– LM Studio é€‚é…å™¨
        
        Args:
            model_id: æ¨¡å‹ IDï¼ˆé»˜è®¤ local-modelï¼‰
            base_url: LM Studio API base URLï¼ˆé»˜è®¤ http://localhost:1234/v1ï¼‰
        """
        super().__init__(
            model_id=model_id,
            base_url=base_url,
            api_key="lm-studio"  # å ä½ç¬¦ï¼ŒLM Studio ä¸éœ€è¦çœŸå® API key
        )
        self.tool_name = "lmstudio"
    
    def health_check(self) -> ToolHealth:
        """
        å¥åº·æ£€æŸ¥ï¼šæ£€æŸ¥ LM Studio æœåŠ¡ + æ¨¡å‹æ˜¯å¦åŠ è½½
        
        æ£€æŸ¥é¡ºåº:
        1. GET /models - æ£€æŸ¥æœåŠ¡æ˜¯å¦å¯è¾¾
        2. è§£ææ¨¡å‹åˆ—è¡¨ - æ£€æŸ¥æ˜¯å¦æœ‰æ¨¡å‹åŠ è½½
        
        ğŸ”’ é’‰å­ 2ï¼šé”™è¯¯å¿…é¡»åˆ†ç±»ï¼ˆè¿ç»´æ’æŸ¥å¿…éœ€ï¼‰
        
        Returns:
            ToolHealth
        """
        if not HAS_REQUESTS:
            return ToolHealth(
                status="unreachable",
                details="requests library not installed",
                error_category="dependency"
            )
        
        try:
            # 1. æ£€æŸ¥æœåŠ¡å¯è¾¾æ€§
            response = requests.get(f"{self.base_url}/models", timeout=5)
            
            if response.status_code != 200:
                return ToolHealth(
                    status="unreachable",
                    details=f"LM Studio returned {response.status_code}. Is the server running?",
                    error_category="network"
                )
            
            # 2. æ£€æŸ¥æ¨¡å‹æ˜¯å¦åŠ è½½
            models_data = response.json()
            models = models_data.get("data", [])
            
            if not models:
                return ToolHealth(
                    status="model_missing",
                    details="No model loaded in LM Studio. Please load a model in the UI.",
                    error_category="model"  # ğŸ”’ é’‰å­ 2ï¼šæ“ä½œæ€§é”™è¯¯
                )
            
            # æå–æ¨¡å‹ ID
            model_ids = [m.get("id", "") for m in models]
            model_list = ', '.join(model_ids[:3])
            if len(model_ids) > 3:
                model_list += f" (+{len(model_ids) - 3} more)"
            
            return ToolHealth(
                status="connected",
                details=f"LM Studio connected, models: {model_list}"
            )
            
        except Exception as e:
            if HAS_REQUESTS and hasattr(requests, 'exceptions'):
                if isinstance(e, (requests.exceptions.ConnectionError, requests.exceptions.Timeout)):
                    return ToolHealth(
                        status="unreachable",
                        details=f"Cannot connect to LM Studio: {e}",
                        error_category="network"
                    )
            return ToolHealth(
                status="unreachable",
                details=f"Health check failed: {e}",
                error_category="runtime"
            )
    
    def supports(self) -> ToolCapabilities:
        """
        å£°æ˜ LM Studio èƒ½åŠ›
        
        ğŸ”’ é’‰å­ 1ï¼šMode System å¿…é¡»çŸ¥é“æ¨¡å‹èƒ½åŠ›
        """
        return ToolCapabilities(
            execution_mode="local",
            supports_diff=True,
            supports_patch=True,
            supports_health_check=True,
            # ğŸ”’ é’‰å­ 1ï¼šæ¨¡å‹èƒ½åŠ›ï¼ˆMode System å¿…éœ€ï¼‰
            chat=True,
            json_mode=False,  # LM Studio å–å†³äºåŠ è½½çš„æ¨¡å‹
            function_call=False,
            stream=True,  # LM Studio æ”¯æŒæµå¼
            long_context=False,  # å–å†³äºåŠ è½½çš„æ¨¡å‹
            diff_quality="medium"  # æœ¬åœ°æ¨¡å‹é€šå¸¸æ˜¯ medium
        )

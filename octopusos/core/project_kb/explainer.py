"""ç»“æœè§£é‡Šå™¨ - ç”Ÿæˆäººç±»å¯è¯»çš„æ£€ç´¢ç»“æœè§£é‡Š

æ ¸å¿ƒåŠŸèƒ½:
- å°† Explanation å¯¹è±¡è½¬æ¢ä¸ºå¯è¯»æ–‡æœ¬
- è§£é‡Šä¸ºä»€ä¹ˆè¯¥ç»“æœè¢«è¿”å›
- ç¬¦åˆå®¡è®¡è¦æ±‚ (å¯è¿½æº¯ã€å¯ç†è§£)
"""

from agentos.core.project_kb.types import ChunkResult, Explanation


class ResultExplainer:
    """ç»“æœè§£é‡Šå™¨ - å®¡è®¡å…³é”®ç»„ä»¶"""

    def explain_result(self, result: ChunkResult) -> str:
        """ç”Ÿæˆå•ä¸ªç»“æœçš„è§£é‡Š

        Args:
            result: ChunkResult å¯¹è±¡

        Returns:
            äººç±»å¯è¯»çš„è§£é‡Šæ–‡æœ¬
        """
        exp = result.explanation
        lines = []

        # æ ‡é¢˜
        lines.append(f"ğŸ“„ {result.path}")
        if result.heading:
            lines.append(f"   Section: {result.heading}")
        lines.append(f"   Lines: {result.lines}")
        lines.append(f"   Score: {result.score:.2f}")
        lines.append("")

        # åŒ¹é…è¯
        if exp.matched_terms:
            lines.append(f"âœ“ Matched terms: {', '.join(exp.matched_terms)}")
            lines.append(f"  Frequencies: {self._format_frequencies(exp.term_frequencies)}")

        # æƒé‡åŠ æˆ
        boosts = []
        if exp.document_boost != 1.0:
            boosts.append(f"doc_type={exp.document_boost:.2f}x")
        if exp.recency_boost != 1.0:
            boosts.append(f"recency={exp.recency_boost:.2f}x")
        if boosts:
            lines.append(f"  Boosts: {', '.join(boosts)}")

        # [P2] å‘é‡è¯„åˆ† (å¦‚æœæœ‰)
        if exp.vector_score is not None:
            lines.append(f"  Vector score: {exp.vector_score:.3f}")
            if exp.rerank_delta is not None:
                direction = "â†‘" if exp.rerank_delta > 0 else "â†“"
                lines.append(f"  Rerank: {direction} {abs(exp.rerank_delta)} positions")

        return "\n".join(lines)

    def explain_results(self, results: list[ChunkResult], query: str) -> str:
        """ç”Ÿæˆå¤šä¸ªç»“æœçš„æ±‡æ€»è§£é‡Š

        Args:
            results: ChunkResult åˆ—è¡¨
            query: åŸå§‹æŸ¥è¯¢

        Returns:
            äººç±»å¯è¯»çš„æ±‡æ€»è§£é‡Š
        """
        if not results:
            return f"No results found for: {query}"

        lines = []
        lines.append(f"ğŸ” Search: {query}")
        lines.append(f"Found {len(results)} result(s)\n")
        lines.append("=" * 60)

        for i, result in enumerate(results, start=1):
            lines.append(f"\n[{i}] {self.explain_result(result)}")
            lines.append("=" * 60)

        return "\n".join(lines)

    def _format_frequencies(self, term_frequencies: dict[str, int]) -> str:
        """æ ¼å¼åŒ–è¯é¢‘

        Args:
            term_frequencies: è¯ -> é¢‘æ¬¡æ˜ å°„

        Returns:
            æ ¼å¼åŒ–å­—ç¬¦ä¸²
        """
        items = [f"{term}({count})" for term, count in term_frequencies.items()]
        return ", ".join(items)

    def explain_to_json(self, result: ChunkResult) -> dict:
        """å°†è§£é‡Šè½¬æ¢ä¸º JSON æ ¼å¼ (ç”¨äº API)

        Args:
            result: ChunkResult å¯¹è±¡

        Returns:
            JSON-serializable å­—å…¸
        """
        return result.to_dict()

    def explain_scoring(self, explanation: Explanation) -> str:
        """è¯¦ç»†è§£é‡Šè¯„åˆ†è®¡ç®—è¿‡ç¨‹

        Args:
            explanation: Explanation å¯¹è±¡

        Returns:
            è¯„åˆ†è®¡ç®—è§£é‡Š
        """
        lines = []
        lines.append("Scoring breakdown:")

        # åŸºç¡€åˆ†
        if explanation.keyword_score is not None:
            lines.append(f"  Base (keyword): {explanation.keyword_score:.2f}")
        
        # æ–‡æ¡£æƒé‡
        if explanation.document_boost != 1.0:
            lines.append(f"  Ã— Document boost: {explanation.document_boost:.2f}")
        
        # æ–°é²œåº¦æƒé‡
        if explanation.recency_boost != 1.0:
            lines.append(f"  Ã— Recency boost: {explanation.recency_boost:.2f}")
        
        # å‘é‡è¯„åˆ† (P2)
        if explanation.vector_score is not None:
            lines.append(f"  + Vector score: {explanation.vector_score:.3f}")
        
        return "\n".join(lines)

"""
Risk Miner - é£é™©è§„åˆ™æŒ–æ˜å¼•æ“

å®ç°6æ¡MVPé£é™©è§„åˆ™ï¼Œä» Supervisor å†³ç­–å†å²ä¸­è‡ªåŠ¨æŒ–æ˜ç³»ç»Ÿæ€§é£é™©å’Œå¼‚å¸¸æ¨¡å¼ã€‚

ğŸ”’ SEMANTIC FREEZE (F-3): Lead Agent Behavior
----------------------------------------------
Lead Agent is read-only risk miner

âœ… Lead Agent CAN:
   - Read historical governance data (task_audits, events)
   - Detect risk patterns
   - Produce LeadFinding records
   - Create follow-up tasks for human review

âŒ Lead Agent CANNOT:
   - NEVER modify business data (tasks, sessions, etc.)
   - NEVER auto-fix detected issues
   - NEVER apply remediation actions
   - NEVER change system configuration

Guarantee: All Lead Agent operations are READ-ONLY. All remediation requires human approval.
Reference: ADR-004 Section F-3

è§„åˆ™åˆ—è¡¨ï¼š
1. blocked_reason_spike: æŸ finding.code åœ¨24hå†…æ¿€å¢
2. pause_block_churn: åŒä¸€ä»»åŠ¡å¤šæ¬¡ PAUSE åæœ€ç»ˆ BLOCK
3. retry_recommended_but_fails: RETRY å»ºè®®åä»ç„¶å¤±è´¥
4. decision_lag_anomaly: å†³ç­–å»¶è¿Ÿ p95 è¶…é˜ˆå€¼
5. redline_ratio_increase: REDLINE ç±»å‹ finding å æ¯”æ˜¾è‘—ä¸Šå‡
6. high_risk_allow: HIGH/CRITICAL ä¸¥é‡åº¦é—®é¢˜ä»è¢« ALLOW
"""

from dataclasses import dataclass
from typing import Any, Dict, List
import uuid
from collections import defaultdict, Counter

from agentos.core.lead.models import LeadFinding, ScanWindow


@dataclass
class MinerConfig:
    """
    Miner é…ç½®

    æ‰€æœ‰è§„åˆ™çš„é˜ˆå€¼éƒ½å¯é…ç½®ï¼Œæ–¹ä¾¿è°ƒä¼˜å’Œæµ‹è¯•ã€‚
    """
    # è§„åˆ™1: blocked_reason_spike
    spike_threshold: int = 5                    # æ¿€å¢é˜ˆå€¼ï¼ˆcountï¼‰

    # è§„åˆ™2: pause_block_churn
    pause_count_threshold: int = 2              # PAUSE æ¬¡æ•°é˜ˆå€¼

    # è§„åˆ™3: retry_recommended_but_fails
    # ï¼ˆæ— é¢å¤–é˜ˆå€¼ï¼Œæ£€æµ‹ RETRY åæ˜¯å¦æœ‰ BLOCK/FAILEDï¼‰

    # è§„åˆ™4: decision_lag_anomaly
    decision_lag_p95_ms: float = 5000.0         # P95 å»¶è¿Ÿé˜ˆå€¼ï¼ˆæ¯«ç§’ï¼‰

    # è§„åˆ™5: redline_ratio_increase
    redline_ratio_increase: float = 0.10        # å æ¯”å¢å¹…é˜ˆå€¼ï¼ˆå¦‚ 0.10 = 10%ï¼‰
    redline_baseline_ratio: float = 0.05        # åŸºå‡†å æ¯”ï¼ˆç”¨äºåˆ¤æ–­æ˜¯å¦æ˜¾è‘—ï¼‰

    # è§„åˆ™6: high_risk_allow
    # ï¼ˆæ— é˜ˆå€¼ï¼Œç›´æ¥æ£€æµ‹ HIGH/CRITICAL + ALLOW ç»„åˆï¼‰


class RiskMiner:
    """
    é£é™©è§„åˆ™æŒ–æ˜å¼•æ“

    ä» storage_data ä¸­åº”ç”¨å¤šæ¡è§„åˆ™ï¼Œè¾“å‡º LeadFinding åˆ—è¡¨ã€‚
    """

    # å¥‘çº¦ç‰ˆæœ¬ï¼šå®šä¹‰ RiskMiner æœŸæœ›çš„è¾“å…¥æ•°æ®æ ¼å¼
    CONTRACT_VERSION = "1.0.0"

    # å¥‘çº¦è¯´æ˜ï¼š
    # v1.0.0: åˆå§‹ç‰ˆæœ¬
    # - æœŸæœ›è¾“å…¥æ ¼å¼ï¼š{findings: [...], decisions: [...], metrics: {...}}
    # - findings æ ¼å¼ï¼š[{code, kind, task_ids, count}]
    # - decisions æ ¼å¼ï¼š[{task_id, decision_id, status, risk_level, action}]

    def __init__(self, config: MinerConfig = None):
        """
        åˆå§‹åŒ– Miner

        Args:
            config: Miner é…ç½®ï¼Œå¦‚æœä¸º None åˆ™ä½¿ç”¨é»˜è®¤é…ç½®
        """
        self.config = config or MinerConfig()

    def mine_risks(
        self,
        storage_data: Dict[str, Any],
        window: ScanWindow
    ) -> List[LeadFinding]:
        """
        æ‰§è¡Œé£é™©æŒ–æ˜

        Args:
            storage_data: ä» LeadStorage è¿”å›çš„æ•°æ®å­—å…¸ï¼ŒåŒ…å«ï¼š
                - decisions: List[Dict] - å†³ç­–è®°å½•åˆ—è¡¨
                - findings: List[Dict] - å‘ç°è®°å½•åˆ—è¡¨
                - metrics: Dict - æ€§èƒ½æŒ‡æ ‡
            window: æ‰«ææ—¶é—´çª—å£

        Returns:
            LeadFinding åˆ—è¡¨
        """
        findings = []

        # è§„åˆ™1: blocked_reason_spike
        findings.extend(self._rule_blocked_reason_spike(storage_data, window))

        # è§„åˆ™2: pause_block_churn
        findings.extend(self._rule_pause_block_churn(storage_data, window))

        # è§„åˆ™3: retry_recommended_but_fails
        findings.extend(self._rule_retry_recommended_but_fails(storage_data, window))

        # è§„åˆ™4: decision_lag_anomaly
        findings.extend(self._rule_decision_lag_anomaly(storage_data, window))

        # è§„åˆ™5: redline_ratio_increase
        findings.extend(self._rule_redline_ratio_increase(storage_data, window))

        # è§„åˆ™6: high_risk_allow
        findings.extend(self._rule_high_risk_allow(storage_data, window))

        return findings

    def _rule_blocked_reason_spike(
        self,
        storage_data: Dict[str, Any],
        window: ScanWindow
    ) -> List[LeadFinding]:
        """
        è§„åˆ™1: blocked_reason_spike

        æ£€æµ‹24hå†…æŸ finding.code æ¿€å¢ï¼ˆcount > thresholdï¼‰ã€‚

        é€»è¾‘ï¼š
        1. ç»Ÿè®¡æ¯ä¸ª finding.code çš„å‡ºç°æ¬¡æ•°
        2. å¯¹äº count > threshold çš„ codeï¼Œç”Ÿæˆ finding

        Evidence:
        - count: å‡ºç°æ¬¡æ•°
        - samples: æ ·ä¾‹ decision_id åˆ—è¡¨ï¼ˆæœ€å¤š5ä¸ªï¼‰
        """
        findings_list = storage_data.get("findings", [])
        decisions = storage_data.get("decisions", [])

        # ç»Ÿè®¡æ¯ä¸ª code çš„å‡ºç°æ¬¡æ•°å’Œå…³è”çš„ decision_id
        code_stats = defaultdict(lambda: {"count": 0, "decision_ids": []})

        for finding in findings_list:
            code = finding.get("code", "")
            decision_id = finding.get("decision_id", "")

            if code:
                code_stats[code]["count"] += 1
                if decision_id:
                    code_stats[code]["decision_ids"].append(decision_id)

        # æ£€æµ‹æ¿€å¢
        result = []
        for code, stats in code_stats.items():
            if stats["count"] > self.config.spike_threshold:
                # ç”Ÿæˆ fingerprint
                fingerprint = LeadFinding.generate_fingerprint(
                    rule_code="blocked_reason_spike",
                    window=window,
                    dimensions={"finding_code": code}
                )

                # å–æ ·ä¾‹ï¼ˆæœ€å¤š5ä¸ªï¼‰
                samples = stats["decision_ids"][:5]

                finding = LeadFinding(
                    finding_id=f"lead_{uuid.uuid4().hex[:12]}",
                    fingerprint=fingerprint,
                    rule_code="blocked_reason_spike",
                    severity="high",
                    title=f"Finding code '{code}' spiked",
                    description=(
                        f"Finding code '{code}' appeared {stats['count']} times "
                        f"in the last 24h, exceeding threshold of {self.config.spike_threshold}"
                    ),
                    evidence={
                        "count": stats["count"],
                        "finding_code": code,
                        "sample_decision_ids": samples
                    },
                    window=window
                )
                result.append(finding)

        return result

    def _rule_pause_block_churn(
        self,
        storage_data: Dict[str, Any],
        window: ScanWindow
    ) -> List[LeadFinding]:
        """
        è§„åˆ™2: pause_block_churn

        æ£€æµ‹åŒä¸€ä»»åŠ¡å¤šæ¬¡ PAUSE åæœ€ç»ˆ BLOCKã€‚

        é€»è¾‘ï¼š
        1. æŒ‰ task_id åˆ†ç»„å†³ç­–
        2. ç»Ÿè®¡æ¯ä¸ª task çš„ PAUSE æ¬¡æ•°
        3. æ£€æŸ¥æœ€ç»ˆå†³ç­–æ˜¯å¦ä¸º BLOCK
        4. å¦‚æœ PAUSE >= threshold ä¸”æœ€ç»ˆ BLOCKï¼Œç”Ÿæˆ finding

        Evidence:
        - task_id: ä»»åŠ¡ ID
        - pause_count: PAUSE æ¬¡æ•°
        - final_decision: æœ€ç»ˆå†³ç­–ç±»å‹
        - sample_decision_ids: æ ·ä¾‹ decision_idï¼ˆåŒ…å« PAUSE å’Œ BLOCKï¼‰
        """
        decisions = storage_data.get("decisions", [])

        # æŒ‰ task_id åˆ†ç»„
        task_decisions = defaultdict(list)
        for decision in decisions:
            task_id = decision.get("task_id")
            if task_id:
                task_decisions[task_id].append(decision)

        # æ£€æµ‹ pause-block æ¨¡å¼
        result = []
        for task_id, task_dec_list in task_decisions.items():
            # æŒ‰æ—¶é—´æ’åºï¼ˆå‡è®¾ decision_id æˆ– timestamp å¯æ’åºï¼‰
            sorted_decs = sorted(
                task_dec_list,
                key=lambda d: d.get("timestamp", d.get("decision_id", ""))
            )

            # ç»Ÿè®¡ PAUSE æ¬¡æ•°
            pause_count = sum(
                1 for d in sorted_decs
                if d.get("decision_type") == "PAUSE"
            )

            # æ£€æŸ¥æœ€ç»ˆå†³ç­–
            if sorted_decs:
                final_decision = sorted_decs[-1].get("decision_type")

                if pause_count >= self.config.pause_count_threshold and final_decision == "BLOCK":
                    # ç”Ÿæˆ fingerprint
                    fingerprint = LeadFinding.generate_fingerprint(
                        rule_code="pause_block_churn",
                        window=window,
                        dimensions={"task_id": task_id}
                    )

                    # å–æ ·ä¾‹ï¼ˆPAUSE å’Œ BLOCK å†³ç­–ï¼‰
                    pause_samples = [
                        d["decision_id"] for d in sorted_decs
                        if d.get("decision_type") == "PAUSE"
                    ][:3]
                    block_sample = [sorted_decs[-1]["decision_id"]]
                    samples = pause_samples + block_sample

                    finding = LeadFinding(
                        finding_id=f"lead_{uuid.uuid4().hex[:12]}",
                        fingerprint=fingerprint,
                        rule_code="pause_block_churn",
                        severity="medium",
                        title=f"Task {task_id} churned through PAUSE then BLOCK",
                        description=(
                            f"Task {task_id} was PAUSED {pause_count} times "
                            f"before being BLOCKED"
                        ),
                        evidence={
                            "task_id": task_id,
                            "pause_count": pause_count,
                            "final_decision": final_decision,
                            "sample_decision_ids": samples
                        },
                        window=window
                    )
                    result.append(finding)

        return result

    def _rule_retry_recommended_but_fails(
        self,
        storage_data: Dict[str, Any],
        window: ScanWindow
    ) -> List[LeadFinding]:
        """
        è§„åˆ™3: retry_recommended_but_fails

        æ£€æµ‹ RETRY å»ºè®®åä»ç„¶å¤±è´¥ï¼ˆBLOCK æˆ–ç³»ç»Ÿå¤±è´¥ï¼‰ã€‚

        é€»è¾‘ï¼š
        1. æ‰¾åˆ°æ‰€æœ‰ decision_type = RETRY çš„å†³ç­–
        2. å¯¹äºæ¯ä¸ª RETRY å†³ç­–ï¼Œæ£€æŸ¥åŒä¸€ task åç»­æ˜¯å¦æœ‰ BLOCK æˆ–å¤±è´¥
        3. å¦‚æœæœ‰ï¼Œç”Ÿæˆ finding

        Evidence:
        - task_id: ä»»åŠ¡ ID
        - retry_decision_id: RETRY å†³ç­– ID
        - failed_decision_id: å¤±è´¥å†³ç­– ID
        - failed_decision_type: å¤±è´¥å†³ç­–ç±»å‹
        """
        decisions = storage_data.get("decisions", [])

        # æŒ‰ task_id åˆ†ç»„
        task_decisions = defaultdict(list)
        for decision in decisions:
            task_id = decision.get("task_id")
            if task_id:
                task_decisions[task_id].append(decision)

        # æ£€æµ‹ RETRY åå¤±è´¥
        result = []
        for task_id, task_dec_list in task_decisions.items():
            # æŒ‰æ—¶é—´æ’åº
            sorted_decs = sorted(
                task_dec_list,
                key=lambda d: d.get("timestamp", d.get("decision_id", ""))
            )

            # æ‰¾åˆ°æ‰€æœ‰ RETRY å†³ç­–
            for i, decision in enumerate(sorted_decs):
                if decision.get("decision_type") == "RETRY":
                    retry_decision_id = decision.get("decision_id")

                    # æ£€æŸ¥åç»­æ˜¯å¦æœ‰ BLOCK
                    for j in range(i + 1, len(sorted_decs)):
                        subsequent = sorted_decs[j]
                        if subsequent.get("decision_type") == "BLOCK":
                            # ç”Ÿæˆ fingerprint
                            fingerprint = LeadFinding.generate_fingerprint(
                                rule_code="retry_recommended_but_fails",
                                window=window,
                                dimensions={
                                    "task_id": task_id,
                                    "retry_decision_id": retry_decision_id
                                }
                            )

                            finding = LeadFinding(
                                finding_id=f"lead_{uuid.uuid4().hex[:12]}",
                                fingerprint=fingerprint,
                                rule_code="retry_recommended_but_fails",
                                severity="medium",
                                title=f"Task {task_id} failed after RETRY recommendation",
                                description=(
                                    f"Task {task_id} was recommended to RETRY "
                                    f"but subsequently got BLOCKED"
                                ),
                                evidence={
                                    "task_id": task_id,
                                    "retry_decision_id": retry_decision_id,
                                    "failed_decision_id": subsequent.get("decision_id"),
                                    "failed_decision_type": "BLOCK"
                                },
                                window=window
                            )
                            result.append(finding)
                            break  # åªæŠ¥å‘Šç¬¬ä¸€æ¬¡å¤±è´¥

        return result

    def _rule_decision_lag_anomaly(
        self,
        storage_data: Dict[str, Any],
        window: ScanWindow
    ) -> List[LeadFinding]:
        """
        è§„åˆ™4: decision_lag_anomaly

        æ£€æµ‹å†³ç­–å»¶è¿Ÿ p95 è¶…è¿‡é˜ˆå€¼ã€‚

        é€»è¾‘ï¼š
        1. ä» metrics ä¸­æå–æ‰€æœ‰å†³ç­–å»¶è¿Ÿ
        2. è®¡ç®— p95
        3. å¦‚æœ p95 > thresholdï¼Œç”Ÿæˆ finding

        Evidence:
        - p95_latency_ms: P95 å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰
        - sample_count: æ ·æœ¬æ•°é‡
        - threshold_ms: é˜ˆå€¼
        """
        metrics = storage_data.get("metrics", {})

        # æå–å»¶è¿Ÿæ•°æ®ï¼ˆå‡è®¾ metrics åŒ…å« decision_latenciesï¼‰
        latencies = metrics.get("decision_latencies", [])

        if not latencies:
            return []

        # è®¡ç®— p95
        sorted_latencies = sorted(latencies)
        p95_index = int(len(sorted_latencies) * 0.95)
        p95_latency = sorted_latencies[p95_index] if p95_index < len(sorted_latencies) else sorted_latencies[-1]

        # æ£€æŸ¥æ˜¯å¦è¶…é˜ˆå€¼
        if p95_latency > self.config.decision_lag_p95_ms:
            # ç”Ÿæˆ fingerprintï¼ˆå…¨å±€ï¼Œä¸æŒ‰ç»´åº¦ç»†åˆ†ï¼‰
            fingerprint = LeadFinding.generate_fingerprint(
                rule_code="decision_lag_anomaly",
                window=window,
                dimensions={}
            )

            finding = LeadFinding(
                finding_id=f"lead_{uuid.uuid4().hex[:12]}",
                fingerprint=fingerprint,
                rule_code="decision_lag_anomaly",
                severity="high",
                title="Decision latency p95 exceeded threshold",
                description=(
                    f"Decision latency p95 is {p95_latency:.1f}ms, "
                    f"exceeding threshold of {self.config.decision_lag_p95_ms}ms"
                ),
                evidence={
                    "p95_latency_ms": p95_latency,
                    "sample_count": len(latencies),
                    "threshold_ms": self.config.decision_lag_p95_ms
                },
                window=window
            )
            return [finding]

        return []

    def _rule_redline_ratio_increase(
        self,
        storage_data: Dict[str, Any],
        window: ScanWindow
    ) -> List[LeadFinding]:
        """
        è§„åˆ™5: redline_ratio_increase

        æ£€æµ‹ REDLINE ç±»å‹ finding å æ¯”æ˜¾è‘—ä¸Šå‡ã€‚

        é€»è¾‘ï¼š
        1. ç»Ÿè®¡ REDLINE ç±»å‹ finding çš„æ•°é‡
        2. è®¡ç®— REDLINE å æ¯”ï¼ˆREDLINE / total findingsï¼‰
        3. å¦‚æœå æ¯”æ˜¾è‘—é«˜äºåŸºå‡†ï¼ˆå¦‚ä» 5% æ¶¨åˆ° 20%ï¼‰ï¼Œç”Ÿæˆ finding

        Evidence:
        - redline_count: REDLINE ç±»å‹æ•°é‡
        - total_count: æ€» finding æ•°é‡
        - redline_ratio: REDLINE å æ¯”
        - baseline_ratio: åŸºå‡†å æ¯”
        """
        findings_list = storage_data.get("findings", [])

        if not findings_list:
            return []

        # ç»Ÿè®¡ REDLINE æ•°é‡
        redline_count = sum(
            1 for f in findings_list
            if f.get("kind") == "REDLINE"
        )
        total_count = len(findings_list)

        # è®¡ç®—å æ¯”
        redline_ratio = redline_count / total_count if total_count > 0 else 0.0

        # æ£€æŸ¥å æ¯”æ˜¯å¦æ˜¾è‘—ä¸Šå‡
        baseline = self.config.redline_baseline_ratio
        increase = redline_ratio - baseline

        if increase > self.config.redline_ratio_increase:
            # ç”Ÿæˆ fingerprint
            fingerprint = LeadFinding.generate_fingerprint(
                rule_code="redline_ratio_increase",
                window=window,
                dimensions={}
            )

            finding = LeadFinding(
                finding_id=f"lead_{uuid.uuid4().hex[:12]}",
                fingerprint=fingerprint,
                rule_code="redline_ratio_increase",
                severity="high",
                title="REDLINE findings ratio increased significantly",
                description=(
                    f"REDLINE findings ratio is {redline_ratio:.2%}, "
                    f"increased by {increase:.2%} from baseline {baseline:.2%}"
                ),
                evidence={
                    "redline_count": redline_count,
                    "total_count": total_count,
                    "redline_ratio": redline_ratio,
                    "baseline_ratio": baseline,
                    "increase": increase
                },
                window=window
            )
            return [finding]

        return []

    def _rule_high_risk_allow(
        self,
        storage_data: Dict[str, Any],
        window: ScanWindow
    ) -> List[LeadFinding]:
        """
        è§„åˆ™6: high_risk_allow

        æ£€æµ‹ HIGH/CRITICAL ä¸¥é‡åº¦çš„ finding ä»è¢« ALLOWã€‚

        é€»è¾‘ï¼š
        1. æ‰¾åˆ°æ‰€æœ‰ decision_type = ALLOW çš„å†³ç­–
        2. æ£€æŸ¥è¿™äº›å†³ç­–ä¸­æ˜¯å¦æœ‰ HIGH æˆ– CRITICAL çš„ findings
        3. å¦‚æœæœ‰ï¼Œç”Ÿæˆ finding

        Evidence:
        - count: è¿è§„å†³ç­–æ•°é‡
        - sample_decision_ids: æ ·ä¾‹å†³ç­– IDï¼ˆæœ€å¤š5ä¸ªï¼‰
        """
        decisions = storage_data.get("decisions", [])
        findings_list = storage_data.get("findings", [])

        # æ„å»º decision_id -> findings çš„æ˜ å°„
        decision_findings = defaultdict(list)
        for finding in findings_list:
            decision_id = finding.get("decision_id")
            if decision_id:
                decision_findings[decision_id].append(finding)

        # æ£€æµ‹ HIGH/CRITICAL + ALLOW ç»„åˆ
        violation_decision_ids = []

        for decision in decisions:
            if decision.get("decision_type") == "ALLOW":
                decision_id = decision.get("decision_id")
                related_findings = decision_findings.get(decision_id, [])

                # æ£€æŸ¥æ˜¯å¦æœ‰ HIGH æˆ– CRITICAL çš„ findings
                has_high_risk = any(
                    f.get("severity") in ["HIGH", "CRITICAL"]
                    for f in related_findings
                )

                if has_high_risk:
                    violation_decision_ids.append(decision_id)

        # ç”Ÿæˆ finding
        if violation_decision_ids:
            # ç”Ÿæˆ fingerprint
            fingerprint = LeadFinding.generate_fingerprint(
                rule_code="high_risk_allow",
                window=window,
                dimensions={}
            )

            # å–æ ·ä¾‹ï¼ˆæœ€å¤š5ä¸ªï¼‰
            samples = violation_decision_ids[:5]

            finding = LeadFinding(
                finding_id=f"lead_{uuid.uuid4().hex[:12]}",
                fingerprint=fingerprint,
                rule_code="high_risk_allow",
                severity="critical",
                title="HIGH/CRITICAL findings allowed to proceed",
                description=(
                    f"Found {len(violation_decision_ids)} decisions that ALLOWED "
                    f"tasks despite HIGH or CRITICAL severity findings"
                ),
                evidence={
                    "count": len(violation_decision_ids),
                    "sample_decision_ids": samples
                },
                window=window
            )
            return [finding]

        return []
